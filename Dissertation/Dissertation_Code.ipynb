{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737f5f14",
   "metadata": {},
   "source": [
    "# Dissertation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3073d9",
   "metadata": {},
   "source": [
    "## Research into the techniques and methods to achieve state of the art accuracy in flower species identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6984ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###imports###\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy import io\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import logging\n",
    "import skimage.io\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa11d15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a43f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed53ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tf.test.gpu_device_name(): \n",
    "\n",
    "#     print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "# else:\n",
    "\n",
    "#     print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes all outputs be in float format rather than exponentials\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c860a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "IMG_SIZE = 100 #this parameter sets image dimensions as 50*50\n",
    "DATE = datetime.datetime.now().strftime('%d-%b-%Y')\n",
    "MODEL_PATH = f'models/{DATE}/'\n",
    "MODEL_NAME = 'FlowerClassifierTrial.model'.format(int(time.time()))\n",
    "TENSORBOARD = TensorBoard(log_dir=f'logs\\\\{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c687c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbdd12",
   "metadata": {},
   "source": [
    "# Load Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1c4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Directory for MacBook\n",
    "mac_URL = '/Volumes/T7/Uni/Github/thesis/flowerDataset/Flower'\n",
    "mac_labels = '/Volumes/T7/Uni/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "mac_dataSplit = '/Volumes/T7/Uni/Github/thesis/flowerDataset/setid.mat'\n",
    "mac_loaded_images = '/Volumes/T7/Uni/loaded_images.npy'\n",
    "mac_image_train='/Volumes/T7/Uni/image_train.npy'\n",
    "mac_label_train = '/Volumes/T7/Uni/label_train.npy'\n",
    "mac_image_test = '/Volumes/T7/Uni/image_test.npy'\n",
    "mac_label_test = '/Volumes/T7/Uni/label_test.npy'\n",
    "mac_image_val = '/Volumes/T7/Uni/image_val.npy'\n",
    "mac_label_val = '/Volumes/T7/Uni/label_val.npy'\n",
    "\n",
    "###Directory for PC\n",
    "pc_labels = 'E:/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "pc_URL = 'E:/Github/thesis/flowerDataset/Flower'\n",
    "pc_dataSplit = 'E:/Github/thesis/flowerDataset/setid.mat'\n",
    "pc_loaded_images = 'E:/Dissertation/loaded_images.npy'\n",
    "pc_image_train = 'E:/Dissertation/image_train.npy'\n",
    "pc_label_train = 'E:/Dissertation/label_train.npy'\n",
    "pc_image_test = 'E:/Dissertation/image_test.npy'\n",
    "pc_label_test = 'E:/Dissertation/label_test.npy'\n",
    "pc_image_val = 'E:/Dissertation/image_val.npy'\n",
    "pc_label_val = 'E:/Dissertation/label_val.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1180309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories():\n",
    "    if os.path.exists(mac_URL) and os.path.exists(mac_labels) and os.path.exists(\n",
    "            mac_dataSplit) and os.path.exists(mac_loadedImages):\n",
    "        return mac_URL, mac_labels, mac_dataSplit, mac_loaded_images, mac_image_train, mac_label_train, mac_image_test, mac_label_test,mac_image_val, mac_label_val \n",
    "    else:\n",
    "        return pc_labels, pc_URL, pc_dataSplit, pc_loaded_images, pc_image_train, pc_label_train, pc_image_test, pc_label_test, pc_image_val, pc_label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04ec1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir, URL_dir, dataSplit_dir, loaded_images_dir, image_train_dir, label_train_dir, image_test_dir, label_test_dir, image_val_dir, label_val_dir = get_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f0c1a",
   "metadata": {},
   "source": [
    "### Load DataSet and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b53f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = io.loadmat(labels_dir)\n",
    "data_labels = data_labels.items()\n",
    "data_labels = list(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c2554af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41c40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1][3][0] #loads the labels that is stored in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a0b6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 77, 77, ..., 62, 62, 62], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b102eefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIQUE_LABELS = np.unique(labels)\n",
    "UNIQUE_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ff41223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got loading files code from link below\n",
    "#https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "#Function gets all the images loaded up\n",
    "def load_images_from_folder(URL):\n",
    "    images = []\n",
    "    for filename in os.listdir(URL):\n",
    "        #img = cv2.imread(os.path.join(URL,filename))\n",
    "        img = cv2.resize(cv2.imread(os.path.join(URL,filename), cv2.COLOR_BGR2RGB), (IMG_SIZE, IMG_SIZE))\n",
    "        img = np.reshape(img,[IMG_SIZE,IMG_SIZE,3])\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    np.save(loaded_images_dir, images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "563d6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to run this cell if image already loaded.\n",
    "#load_images_from_folder(URL_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b32b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if images are already loaded, just load the file here rather than running function again.\n",
    "#image_data = np.load(loaded_images_dir, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0969fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows the shape of the image_data, the number of images, the dimensions and number of colour channels\n",
    "#image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5eec5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4356b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine image with labels\n",
    "def randomised_dataset(image_data, labels):\n",
    "    np.random.seed(8)\n",
    "    indices = np.arange(image_data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    image_data = image_data[indices]\n",
    "    labels = labels[indices]\n",
    "    return image_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4efd03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "labels = np.array(mlb.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6dc2e",
   "metadata": {},
   "source": [
    "# Training and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64e30768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation code from https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "#splitting the image dataset into the ratio for training, validation adn testing data\n",
    "def split_data(image_data, labels):\n",
    "    \n",
    "    train_ratio = 0.75\n",
    "    validation_ratio = 0.15\n",
    "    test_ratio = 0.10\n",
    "\n",
    "    image_train, image_test, label_train, label_test = train_test_split(image_data, labels, test_size=1 - train_ratio)\n",
    "\n",
    "    #the test from previous line which is 25% of dataset is passed into the line below to be \n",
    "    #further split into 15% for validation and 10% for testing\n",
    "\n",
    "    image_val, image_test, label_val, label_test = train_test_split(image_test, label_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "    print('image_train',image_train.shape)\n",
    "    print('label_train',label_train.shape)\n",
    "    print('image_test',image_test.shape)\n",
    "    print('label_test',label_test.shape)\n",
    "    print('image_val', image_val.shape)\n",
    "    print('label_val', label_val.shape)\n",
    "\n",
    "    np.save(image_train_dir, image_train)\n",
    "    np.save(label_train_dir, label_train)\n",
    "    np.save(image_test_dir, image_test)\n",
    "    np.save(label_test_dir, label_test)\n",
    "    np.save(image_val_dir, image_val)\n",
    "    np.save(label_val_dir, label_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d348125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the images and labels into training and testing sets. The percentage is set by test_size variable.\n",
    "def split_data_original(image_data, labels):\n",
    "    image_train,image_test,label_train,label_test=train_test_split(image_data,labels,test_size=0.2)\n",
    "    np.save(image_train_dir, image_train)\n",
    "    np.save(image_test_dir, image_test)\n",
    "    np.save(label_train.npy_dir, label_train)\n",
    "    np.save(label_test_dir, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d985813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_data(image_data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aee55642",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = np.load(image_train_dir, allow_pickle=True)\n",
    "image_test = np.load(image_test_dir, allow_pickle=True)\n",
    "label_train = np.load(label_train_dir, allow_pickle=True)\n",
    "label_test = np.load(label_test_dir, allow_pickle=True)\n",
    "image_val = np.load(image_val_dir, allow_pickle=True)\n",
    "label_val = np.load(label_val_dir, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606a621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 100, 100, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14a99e",
   "metadata": {},
   "source": [
    "# Labels reformatting <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c95ea",
   "metadata": {},
   "source": [
    "### converting 1d array into multidimensional arrays<br> might need to delete this section not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4b3677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_train_label(label_train):\n",
    "    train_labels = []\n",
    "    for i in range(len(label_train)):\n",
    "        train_labels.insert(i, [label_train[i]])\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3ee56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to convert labels\n",
    "#train_labels = convert_train_label(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89dbb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_test_label(label_test):\n",
    "    test_labels = []\n",
    "    for i in range(len(label_test)):\n",
    "        test_labels.insert(i, [label_test[i]])\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b3264c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to convert labels\n",
    "#test_labels = convert_test_label(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "941c9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_val_label(label_val):\n",
    "    val_labels = []\n",
    "    for i in range(len(label_val)):\n",
    "        val_labels.insert(i, [label_val[i]])\n",
    "    return val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1600232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run to convert labels\n",
    "#val_labels = convert_val_label(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6404dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Override the labels files\n",
    "#np.save('/Volumes/T7/Uni/label_train.npy', train_labels)\n",
    "#np.save('/Volumes/T7/Uni/label_test.npy', test_labels)\n",
    "#np.save('/Volumes/T7/Uni/label_val.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d027f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_train = np.load('/Volumes/T7/Uni/label_train.npy', allow_pickle=True)\n",
    "#label_test = np.load('/Volumes/T7/Uni/label_test.npy', allow_pickle=True)\n",
    "#label_val = np.load('/Volumes/T7/Uni/label_val.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a1187",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff6920dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the images to the range of 0 - 1.0 \n",
    "image_train = image_train/255.0\n",
    "image_test = image_test/255.0\n",
    "image_val = image_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1bb389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 100, 100, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e534027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 102)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "312de917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 102)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac508a3",
   "metadata": {},
   "source": [
    "## Find unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27bb0e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6141"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55d0ae0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of classes/ flowers\n",
    "NUM_CLASSES = len(labels[0])\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18204d6a",
   "metadata": {},
   "source": [
    "# Custom CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc375b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of model\n",
    "name_model = 'test-{}'.format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcd25759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(name_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81c56ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "epochs = 30\n",
    "verbose= 0\n",
    "act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc5b2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(act, verbose):\n",
    "    model = Sequential()\n",
    "    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "    \n",
    "    # INPUT LAYER\n",
    "    model.add(Conv2D(32, (3, 3), activation=act, input_shape=input_shape))\n",
    "    ## model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # HIDDEN LAYER 1\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # HIDDEN LAYER 2\n",
    "    model.add(Conv2D(64, (3, 3), activation=act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # HIDDEN LAYER 3\n",
    "    model.add(Conv2D(128, (3, 3), activation=act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # HIDDEN LAYER 4\n",
    "    model.add(Conv2D(256, (3, 3), activation=act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # Fully Connected\n",
    "    model.add(Flatten()) # converts the 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.25)) # reduces overfitting\n",
    "\n",
    "    # OUTPUT LAYER\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6803cb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_cnn_model(act, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53d5fff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 102)               26214     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 102)               0         \n",
      "=================================================================\n",
      "Total params: 1,474,630\n",
      "Trainable params: 1,473,670\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8e4405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(image_train, label_train, batch_size=6, epochs=35, validation_data=(image_val, label_val), verbose=2, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7e4887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "#model.save(f'{MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff2059af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model\n",
    "#model =  tf.keras.models.load_model(f'{MODEL_PATH}')\n",
    "#model = tf.keras.models.load_model(f'E:/GoogleSync/Masters/Dissertation/models/24-Jun-2021') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170a1d3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27a9ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c30171a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-81ae8449850d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#               metrics=['accuracy'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Fit our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36msafe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"succeeded\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mpatch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 \u001b[1;31m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\mlflow\\keras.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[0munlogged_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"validation_data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"verbose\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_run_and_log_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlogged_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\mlflow\\keras.py\u001b[0m in \u001b[0;36m_run_and_log_function\u001b[1;34m(self, original, args, kwargs, unlogged_params, callback_arg_index)\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[0mtry_mlflow_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_log_early_stop_callback_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             try_mlflow_log(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m                                 \u001b[0mdisable_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreroute_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                             ):\n\u001b[1;32m--> 448\u001b[1;33m                                 \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mog_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mog_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                             try_log_autologging_event(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.keras.autolog()\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "        \n",
    "#         model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "#               optimizer=tf.keras.optimizers.Adam(),\n",
    "#               metrics=['accuracy'])\n",
    "        # Fit our model\n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val))\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = 0)\n",
    "        \n",
    "        mlflow.log_param(\"activation function\", activation)\n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        \n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        mlflow.keras.log_model(model, \"standardCNN\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ac114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function that returns loss value & metrics values\n",
    "model.evaluate(image_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ec96c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31c612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78013fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test[0][52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86168ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(image_test, model):\n",
    "    #going through each of the test images\n",
    "    count = 0\n",
    "    for i in range(len(image_test)): #going through all test images\n",
    "        img = image_test[i] #load in the image\n",
    "        \n",
    "        img = img.reshape(-1, 100, 100, 3) #get it in the right shape for model.predict\n",
    "        \n",
    "        prediction = model.predict(img).flatten() #using model predict to get what it thinks is the answer\n",
    "        \n",
    "        # prediction.astype(np.int) #converts predictions to integers\n",
    "        \n",
    "        pred_index = np.argmax(prediction) # grabs the INDEX of the best prediction\n",
    "        \n",
    "        max_pred = max(prediction) # grabs the SCORE of best prediction\n",
    "        # print(prediction)\n",
    "        # print(pred_index)\n",
    "        \n",
    "        test_label_value = label_test[i][pred_index] # gets the actual test label at the same index\n",
    "        # print(test_label_value)\n",
    "        if test_label_value == 1:\n",
    "            #print(\"CORRECT PREDICTION\")\n",
    "            count += 1\n",
    "            \n",
    "#         # FIND THE INDEX WHERE THE VALUE = 1\n",
    "#         for j in range(len(predicted_label)):\n",
    "#             if predicted_label[j] == 1 : #find the point when it finds 1 \n",
    "#                 if label_test[i][j] == 1: #check if at this exact point is also 1  whic means correct prediction\n",
    "#                     count+=1 #increase number of correct count by 1\n",
    "#                     print(count)\n",
    "#                     break\n",
    "    print(f\"num correct - {count}\")\n",
    "    accuracy = (count/len(label_test))*100\n",
    "    per_symbol = '%'\n",
    "    print(f'accuracy is {accuracy} {per_symbol}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad03f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_accuracy(image_test, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks for best model\n",
    "runs = mlflow.search_runs(experiment_ids=experiment_id,\n",
    "                          order_by=['metrics.mae'], max_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1d438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8233bce6",
   "metadata": {},
   "source": [
    "# Segmentation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599480db",
   "metadata": {},
   "source": [
    "# MASK RCNN CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d290bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"E:\\Dissertation\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"data\\img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bfc39",
   "metadata": {},
   "source": [
    "## Extract Masks from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e724bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all the image paths stores in a list\n",
    "def get_img_paths(URL_dir):\n",
    "    img_paths = []\n",
    "    for path in os.listdir(URL_dir):\n",
    "        full_path = os.path.join(URL_dir, path)\n",
    "        if os.path.isfile(full_path):\n",
    "            img_paths.append(full_path)\n",
    "\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34762a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = get_img_paths(URL_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b974129",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots each object on a copy of the image and attempts to remove noise\n",
    "\n",
    "def plot_mask(image, masks):\n",
    "    all_masks = list()\n",
    "    masks = masks.astype(int)\n",
    "    # print(masks.shape)\n",
    "    \n",
    "    for i in range(masks.shape[2]):\n",
    "        temp = np.copy(image)\n",
    "        for j in range(temp.shape[2]):\n",
    "            temp[:,:,j] = temp[:,:,j] * masks[:,:,i]\n",
    "        all_masks.append(temp)\n",
    "#         plt.figure(figsize=(8,8))\n",
    "#         plt.imshow(temp)\n",
    "    # print(f\"Number of masks: {len(all_masks)}\")\n",
    "    return all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665be4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overlay all masks onto a black canvas\n",
    "\n",
    "def combine_mask_objects(masks, shape):\n",
    "    canvas = np.zeros(shape, np.uint8)\n",
    "#     print(\"ORIGINAL CANVAS\")\n",
    "#     plt.figure(figsize=(8,8))\n",
    "#     plt.imshow(canvas)\n",
    "    for i, obj in enumerate(masks):\n",
    "        canvas = cv2.add(canvas, obj)\n",
    "#         plt.figure(figsize=(8,8))\n",
    "#         plt.imshow(canvas)\n",
    "    return canvas\n",
    "\n",
    "### Saves all masks for each image in a separate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(img_id, img, folder):\n",
    "    # checks if the img_id folder exists, if not create one\n",
    "    img = PIL.Image.fromarray(img, 'RGB')\n",
    "    img.save(f'{folder}/{img_id}.png')\n",
    "    return True       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8978a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_masks(folder_name, img_paths):\n",
    "    # checks if the masks folder exists, if not creates one\n",
    "    print(os.getcwd())\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    for img_path in img_paths:\n",
    "        print(img_path)\n",
    "        img_id = Path(img_path).stem\n",
    "        print(img_id)\n",
    "        image = skimage.io.imread(img_path)\n",
    "        # check if image is in rgba format\n",
    "        if image.shape[2] > 3:\n",
    "            # convert to rgb\n",
    "            image = rgba2rgb(image)\n",
    "        # Run detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        # Visualize results\n",
    "        r = results[0]\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], UNIQUE_LABELS, r['scores'])\n",
    "\n",
    "        masks = plot_mask(np.copy(image), r[\"masks\"])\n",
    "\n",
    "        if len(masks) > 0:\n",
    "            processed_image = combine_mask_objects(masks, masks[0].shape)\n",
    "            print(masks)\n",
    "            save_image(i, processed_image, folder_name)\n",
    "        else:\n",
    "            print(f\"{img_id} has no masks!\")\n",
    "            save_image(img_id, image, folder_name)\n",
    "    return \"COMPLETE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(\"E:\\Dissertation\")\n",
    "# os.chdir(path)\n",
    "# UNCOMMENT THIS LINE TO EXTRACT MASKS FROM DATATSET\n",
    "# BEWARE THIS PROCESS CAN TAKE HOURS TO FINISH!\n",
    "generate_masks(\"masks\", img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MASK_DIR = os.path.join(MAIN_PATH, 'data\\train_masks')\n",
    "DEV_SEEN_MASK_DIR = os.path.join(MAIN_PATH, 'data\\dev_seen_masks')\n",
    "DEV_UNSEEN_MASK_DIR = os.path.join(MAIN_PATH, 'data\\dev_unseen_masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce7b56",
   "metadata": {},
   "source": [
    "# 3. Create feature vector of object masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d13d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def extract_id(name):\n",
    "    filename = Path(name).stem\n",
    "    # print(filename)\n",
    "    return filename\n",
    "\n",
    "def generate_data(df, directory):\n",
    "    # dataset con\n",
    "    ids = df[\"id\"].to_numpy()\n",
    "    labels = df[\"label\"].to_numpy()\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        print(root)\n",
    "        count = 0\n",
    "        for file in tqdm(files):\n",
    "            # print(f\"IMAGE: {file}\")\n",
    "            # get full path of the mask\n",
    "            full_path = os.path.join(root, file)\n",
    "            # extract the image id from file\n",
    "            img_id = extract_id(file)\n",
    "            # get tensor of the mask\n",
    "            image = Image.open(full_path)\n",
    "            image = image.resize((224, 224))\n",
    "            image_vect = np.asarray(image)\n",
    "            # print(image_vect.shape)\n",
    "            # find the index for the image_id\n",
    "            idx = np.where(ids == int(img_id))[0][0]\n",
    "            # print(df.iloc[idx])\n",
    "\n",
    "            # get the label for that image_id\n",
    "            label = labels[idx]\n",
    "\n",
    "            # Append features and labels to data lists\n",
    "            X.append(image_vect)\n",
    "            y.append(label)\n",
    "        break\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = generate_data(TRAIN_DF, TRAIN_MASK_DIR)\n",
    "\n",
    "# uncomment to generate training data for dev masks\n",
    "# X, y = generate_data(DEV_SEEN_DF, DEV_SEEN_MASK_DIR)\n",
    "# X, y = generate_data(DEV_UNSEEN_DF, DEV_UNSEEN_MASK_DIR)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c5b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335db64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd41cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29721ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d89c64",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fd133",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet152V2(\n",
    "    input_shape=(224,224,3),\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, # removes last layer of the resnet model\n",
    ")\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(resnet.output)\n",
    "\n",
    "prediction = Dense(1, activation=\"softmax\")(x)\n",
    "\n",
    "resnet_model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad216f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43996e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc119a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1364a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a01fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704716c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb928e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28e2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b90d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db52a23",
   "metadata": {},
   "source": [
    "# GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b52e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4a541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335092d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd45548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649833bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab783d67",
   "metadata": {},
   "source": [
    "# Analysis of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b8c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
