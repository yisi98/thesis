{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "###imports###\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy import io\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import logging\n",
    "#import skimage.io\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from keras.models import Model\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9d145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "NUM_CLASSES = 102\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e731521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0-dev20210716\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c7ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.ImageDataGenerator"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a48cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataset_dir = 'E:/Github/thesis/flowerDataset/Flower/'\n",
    "labels_dir = 'E:/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "new_flower_dataset_dir = 'E:/Github/thesis/flowerDataset/new_flower_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e13df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = io.loadmat(labels_dir)\n",
    "data_labels = data_labels.items()\n",
    "data_labels = list(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0d6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ff0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1][3][0] #loads the labels that is stored in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e586b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee59ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = pd.DataFrame(dict(file_name=os.listdir(orig_dataset_dir),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d966d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfec36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_test = train_test_split(image_data, test_size=1 - train_ratio, random_state=11, stratify=image_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6218a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_val, image_test = train_test_split(image_test, test_size=test_ratio/(test_ratio + validation_ratio),random_state=11) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bb7e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>image_03865.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>image_02027.jpg</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8180</th>\n",
       "      <td>image_08181.jpg</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>image_00719.jpg</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>image_03338.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>image_05908.jpg</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>image_00265.jpg</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>image_05774.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>image_02737.jpg</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>image_07827.jpg</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name  labels\n",
       "3864  image_03865.jpg      17\n",
       "2026  image_02027.jpg      80\n",
       "8180  image_08181.jpg      62\n",
       "718   image_00719.jpg      89\n",
       "3337  image_03338.jpg       8\n",
       "...               ...     ...\n",
       "5907  image_05908.jpg      68\n",
       "264   image_00265.jpg      73\n",
       "5773  image_05774.jpg      13\n",
       "2736  image_02737.jpg      58\n",
       "7826  image_07827.jpg      98\n",
       "\n",
       "[1228 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8947c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flower_dataset_dir = \"E:/Github/thesis/flowerDataset/new_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64dbcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in image_test.to_dict(orient='records'):\n",
    "#     new_dir = new_flower_dataset_dir+'test/'+str(_['labels'])\n",
    "#     if os.path.isdir(new_dir): #check if director exist the copy file\n",
    "#         shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "#     else: #create folder with name label and copy over file \n",
    "#         os.makedirs(new_dir)\n",
    "#         shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82665844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in image_train.to_dict(orient='records'):\n",
    "#     new_dir = new_flower_dataset_dir+'train/'+str(_['labels'])\n",
    "#     if os.path.isdir(new_dir): #check if director exist the copy file\n",
    "#         shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "#     else: #create folder with name label and copy over file \n",
    "#         os.makedirs(new_dir)\n",
    "#         shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a40a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in image_val.to_dict(orient='records'):\n",
    "#     new_dir = new_flower_dataset_dir+'val/'+str(_['labels'])\n",
    "#     if os.path.isdir(new_dir): #check if director exist the copy file\n",
    "#         shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "#     else: #create folder with name label and copy over file \n",
    "#         os.makedirs(new_dir)\n",
    "#         shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a344e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959e7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed17b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6db3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388a5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3547d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(orig_dataset_dir):\n",
    "    images = []\n",
    "    for i, filename in enumerate(os.listdir(orig_dataset_dir)):\n",
    "        #check label[i] value\n",
    "        label = str(labels[i])        \n",
    "        dst_dir = new_flower_dataset_dir+label\n",
    "        if os.path.isdir(dst_dir): #check if director exist the copy file\n",
    "            shutil.copy(orig_dataset_dir+filename, dst_dir)\n",
    "        else: #create folder with name label and copy over file \n",
    "            os.makedirs(dst_dir)\n",
    "            shutil.copy(orig_dataset_dir+filename, dst_dir)\n",
    "            \n",
    "        #if label value folder exists? if not create it else copy image[filename] to new directory\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5293a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_images_from_folder(orig_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05c4711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10648 files belonging to 3 classes.\n",
      "Using 9584 files for training.\n",
      "Found 10648 files belonging to 3 classes.\n",
      "Using 1064 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    new_flower_dataset_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # categorical, binary\n",
    "    # class_names=['0', '1', '2', '3', ...]\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),  # reshape if not in this size\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    new_flower_dataset_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # categorical, binary\n",
    "    # class_names=['0', '1', '2', '3', ...]\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),  # reshape if not in this size\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "883307c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def augment(x, y):\\n    image = tf.image.random_brightness(x, max_delta=0.05)\\n    return image, y\\n\\n\\nds_train = ds_train.map(augment)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def augment(x, y):\n",
    "    image = tf.image.random_brightness(x, max_delta=0.05)\n",
    "    return image, y\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(augment)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "effbc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0201c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "    \n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "\n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b29d9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "optim_1 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#n_steps = ds_train.samples // BATCH_SIZE\n",
    "#n_val_steps = ds_validation.samples // BATCH_SIZE\n",
    "\n",
    "# First we'll train the model without Fine-tuning\n",
    "vgg_model = create_model(input_shape, NUM_CLASSES, optim_1, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4343e06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorboard_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-065ab4beb464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                             callbacks=[tensorboard_callback])\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorboard_callback' is not defined"
     ]
    }
   ],
   "source": [
    "vgg_history = vgg_model.fit(ds_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=ds_validation,\n",
    "                            verbose=2,\n",
    "                            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5c65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307261b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c803e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b41ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0573a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5281150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172ab48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8beea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158e187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
