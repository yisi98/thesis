{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737f5f14",
   "metadata": {},
   "source": [
    "# Dissertation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3073d9",
   "metadata": {},
   "source": [
    "## Research into the techniques and methods to achieve state of the art accuracy in flower species identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e5983c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4d6984ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###imports###\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy import io\n",
    "import tensorflow_hub as hub\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import logging\n",
    "#import skimage.io\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4fa11d15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5a43f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fed53ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ecf1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes all outputs be in float format rather than exponentials\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8c860a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "IMG_SIZE = 224 #this parameter sets image dimensions as 50*50\n",
    "DATE = datetime.datetime.now().strftime('%d-%b-%Y')\n",
    "MODEL_PATH = f'models/{DATE}/'\n",
    "MODEL_NAME = 'TransferResNet152V2.model'.format(int(time.time()))\n",
    "TENSORBOARD = TensorBoard(log_dir=f'logs\\\\{MODEL_NAME}')\n",
    "log_dir=f'logs\\\\{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "48c687c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "796fca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbdd12",
   "metadata": {},
   "source": [
    "# Load Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aee55642",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_dir = 'E:/Github/thesis/flowerDataset/Flower'\n",
    "labels_dir = 'E:/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "dataSplit_dir = 'E:/Github/thesis/flowerDataset/setid.mat'\n",
    "loaded_images_dir = 'E:/Dissertation/loaded_images.npy'\n",
    "image_train_dir ='E:/Dissertation/image_train.npy'\n",
    "label_train_dir = 'E:/Dissertation/label_train.npy'\n",
    "image_test_dir = 'E:/Dissertation/image_test.npy'\n",
    "label_test_dir = 'E:/Dissertation/label_test.npy'\n",
    "image_val_dir = 'E:/Dissertation/image_val.npy'\n",
    "label_val_dir = 'E:/Dissertation/label_val.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "606a621e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_labels = io.loadmat(labels_dir)\n",
    "data_labels = data_labels.items()\n",
    "data_labels = list(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8764eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "954c09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1][3][0] #loads the labels that is stored in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9f42638c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "16fc6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got loading files code from link below\n",
    "#https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "#Function gets all the images loaded up\n",
    "def load_images_from_folder(URL):\n",
    "    images = []\n",
    "    for filename in os.listdir(URL):\n",
    "        #img = cv2.imread(os.path.join(URL,filename))\n",
    "        img = cv2.resize(cv2.imread(os.path.join(URL,filename), cv2.COLOR_BGR2RGB), (IMG_SIZE, IMG_SIZE))\n",
    "        img = np.reshape(img,[IMG_SIZE,IMG_SIZE,3])\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    np.save(loaded_images_dir, images)\n",
    "#################################    return images#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2ce45dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to run this cell if image already loaded.\n",
    "load_images_from_folder(URL_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bfa034b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.load(loaded_images_dir, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "57859247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8189, 224, 224, 3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "09dc7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomised_dataset(image_data, labels):\n",
    "    np.random.seed(8)\n",
    "    indices = np.arange(image_data.shape[0])\n",
    "    print(indices)\n",
    "    np.random.shuffle(indices)\n",
    "    image_data = image_data[indices]\n",
    "    labels = labels[indices]\n",
    "    return image_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "306569b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 8186 8187 8188]\n"
     ]
    }
   ],
   "source": [
    "image_data, labels = randomised_dataset(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "21d46713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Label Encoder\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "converted_labels = np.array(mlb.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8d3a8adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5dbee6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation code from https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "#splitting the image dataset into the ratio for training, validation and testing data\n",
    "def split_data(image_data, converted_labels):\n",
    "    \n",
    "    train_ratio = 0.75\n",
    "    validation_ratio = 0.15\n",
    "    test_ratio = 0.10\n",
    "\n",
    "    image_train, image_test, label_train, label_test = train_test_split(image_data, converted_labels, test_size=1 - train_ratio, random_state=42)\n",
    "\n",
    "    #the test from previous line which is 25% of dataset is passed into the line below to be \n",
    "    #further split into 15% for validation and 10% for testing\n",
    "\n",
    "    image_val, image_test, label_val, label_test = train_test_split(image_test, label_test, test_size=test_ratio/(test_ratio + validation_ratio),random_state=42) \n",
    "\n",
    "    print('image_train',image_train.shape)\n",
    "    print('label_train',label_train.shape)\n",
    "    print('image_test',image_test.shape)\n",
    "    print('label_test',label_test.shape)\n",
    "    print('image_val', image_val.shape)\n",
    "    print('label_val', label_val.shape)\n",
    "\n",
    "    np.save(image_train_dir, image_train)\n",
    "    np.save(label_train_dir, label_train)\n",
    "    np.save(image_test_dir, image_test)\n",
    "    np.save(label_test_dir, label_test)\n",
    "    np.save(image_val_dir, image_val)\n",
    "    np.save(label_val_dir, label_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "714c1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_train (6141, 224, 224, 3)\n",
      "label_train (6141, 102)\n",
      "image_test (820, 224, 224, 3)\n",
      "label_test (820, 102)\n",
      "image_val (1228, 224, 224, 3)\n",
      "label_val (1228, 102)\n"
     ]
    }
   ],
   "source": [
    "split_data(image_data,converted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4b07b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = np.load(image_train_dir, allow_pickle=True)\n",
    "image_test = np.load(image_test_dir, allow_pickle=True)\n",
    "label_train = np.load(label_train_dir, allow_pickle=True)\n",
    "label_test = np.load(label_test_dir, allow_pickle=True)\n",
    "image_val = np.load(image_val_dir, allow_pickle=True)\n",
    "label_val = np.load(label_val_dir, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "74fa7964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 224, 224, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f8272727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#means = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ef84b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stdevs = np.array([58.393, 57.12, 57.375]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "25e8bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_train = (image_train - means)/stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c022a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_test =(image_test - means)/stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a78ff2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_val =(image_val - means)/stdevs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a1187",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ff6920dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #converts the images to the range of 0 - 1.0 \n",
    "image_train = image_train/255.0\n",
    "image_test = image_test/255.0\n",
    "image_val = image_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e1bb389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 224, 224, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4e534027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 102)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "312de917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 102)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4eeeb8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac508a3",
   "metadata": {},
   "source": [
    "## Find unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "27bb0e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6141"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "55d0ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes/ flowers\n",
    "NUM_CLASSES = 102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d89c64",
   "metadata": {},
   "source": [
    "# Transfer Learning --ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aecf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications  import ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "600f7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet152V2(\n",
    "    input_shape=(224,224,3),\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, # removes last layer of the resnet model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b7d5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers: #don't train existing weights\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c48fd133",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(resnet.output)\n",
    "\n",
    "prediction = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b0912eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Total params: 68,567,654\n",
      "Trainable params: 10,236,006\n",
      "Non-trainable params: 58,331,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67a12b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b741ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45dc3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 300\n",
    "verbose= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "415d84fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 530da821be2844f9a198ea661d7d1dbd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-26184bcaf03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tracking_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file:///E:/GoogleSync/Masters/Dissertation/MLflow/mlruns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRUN_NAME\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautolog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf3080\\lib\\site-packages\\mlflow\\tracking\\fluent.py\u001b[0m in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0mexperiment_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_active_run_stack\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnested\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         raise Exception(\n\u001b[0m\u001b[0;32m    172\u001b[0m             (\n\u001b[0;32m    173\u001b[0m                 \u001b[1;34m\"Run with UUID {} is already active. To start a new run, first end the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 530da821be2844f9a198ea661d7d1dbd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"transfer-learning-tests\"\n",
    "RUN_NAME = \"resnet_one_five_two_v_two\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_tracking_uri('file:///E:/GoogleSync/Masters/Dissertation/MLflow/mlruns')\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        \n",
    "        mlflow.tensorflow.autolog()\n",
    "        \n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98fb7f",
   "metadata": {},
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7cf0a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications  import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "927a1ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 15s 0us/step\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet50(\n",
    "    input_shape=(224,224,3),\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False, # removes last layer of the resnet model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "324e9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers: #don't train existing weights\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c61b7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(resnet.output)\n",
    "\n",
    "prediction = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9df307b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Total params: 33,823,718\n",
      "Trainable params: 10,236,006\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aaf0880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "95797bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 300\n",
    "verbose= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8c36edac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/08/14 20:32:15 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... 'input_6_ib-0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... 'input_6_ib-0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "192/192 - 20s - loss: 13.5876 - accuracy: 0.0633 - val_loss: 8.3316 - val_accuracy: 0.1238\n",
      "Epoch 2/300\n",
      "192/192 - 9s - loss: 7.4116 - accuracy: 0.1453 - val_loss: 8.6285 - val_accuracy: 0.1629\n",
      "Epoch 3/300\n",
      "192/192 - 9s - loss: 6.2354 - accuracy: 0.2254 - val_loss: 7.1531 - val_accuracy: 0.1580\n",
      "Epoch 4/300\n",
      "192/192 - 9s - loss: 6.2294 - accuracy: 0.2601 - val_loss: 7.8553 - val_accuracy: 0.1767\n",
      "Epoch 5/300\n",
      "192/192 - 9s - loss: 5.2755 - accuracy: 0.3252 - val_loss: 6.7348 - val_accuracy: 0.2207\n",
      "Epoch 6/300\n",
      "192/192 - 9s - loss: 5.1930 - accuracy: 0.3403 - val_loss: 7.6122 - val_accuracy: 0.1775\n",
      "Epoch 7/300\n",
      "192/192 - 9s - loss: 4.7648 - accuracy: 0.3814 - val_loss: 6.6768 - val_accuracy: 0.2296\n",
      "Epoch 8/300\n",
      "192/192 - 9s - loss: 4.8671 - accuracy: 0.4027 - val_loss: 7.5521 - val_accuracy: 0.2182\n",
      "Epoch 9/300\n",
      "192/192 - 9s - loss: 4.5706 - accuracy: 0.4213 - val_loss: 7.6088 - val_accuracy: 0.2158\n",
      "Epoch 10/300\n",
      "192/192 - 9s - loss: 4.5590 - accuracy: 0.4459 - val_loss: 6.4411 - val_accuracy: 0.2524\n",
      "Epoch 11/300\n",
      "192/192 - 9s - loss: 4.2922 - accuracy: 0.4589 - val_loss: 7.5635 - val_accuracy: 0.1987\n",
      "Epoch 12/300\n",
      "192/192 - 9s - loss: 4.5488 - accuracy: 0.4563 - val_loss: 7.6996 - val_accuracy: 0.2191\n",
      "Epoch 13/300\n",
      "192/192 - 9s - loss: 3.7356 - accuracy: 0.5110 - val_loss: 7.6193 - val_accuracy: 0.2948\n",
      "Epoch 14/300\n",
      "192/192 - 9s - loss: 3.2830 - accuracy: 0.5346 - val_loss: 8.1424 - val_accuracy: 0.2557\n",
      "Epoch 15/300\n",
      "192/192 - 9s - loss: 3.9382 - accuracy: 0.5367 - val_loss: 7.7328 - val_accuracy: 0.2728\n",
      "Epoch 16/300\n",
      "192/192 - 9s - loss: 3.5534 - accuracy: 0.5367 - val_loss: 7.2241 - val_accuracy: 0.2606\n",
      "Epoch 17/300\n",
      "192/192 - 9s - loss: 3.1535 - accuracy: 0.5734 - val_loss: 7.5110 - val_accuracy: 0.2402\n",
      "Epoch 18/300\n",
      "192/192 - 9s - loss: 3.1940 - accuracy: 0.5892 - val_loss: 7.3077 - val_accuracy: 0.2769\n",
      "Epoch 19/300\n",
      "192/192 - 9s - loss: 3.1204 - accuracy: 0.5851 - val_loss: 6.9293 - val_accuracy: 0.2997\n",
      "Epoch 20/300\n",
      "192/192 - 9s - loss: 3.1551 - accuracy: 0.5813 - val_loss: 6.5738 - val_accuracy: 0.2638\n",
      "Epoch 21/300\n",
      "192/192 - 9s - loss: 2.9404 - accuracy: 0.5994 - val_loss: 7.6322 - val_accuracy: 0.2500\n",
      "Epoch 22/300\n",
      "192/192 - 9s - loss: 3.5928 - accuracy: 0.5760 - val_loss: 7.6277 - val_accuracy: 0.2679\n",
      "Epoch 23/300\n",
      "192/192 - 9s - loss: 2.9102 - accuracy: 0.6207 - val_loss: 7.9533 - val_accuracy: 0.2647\n",
      "Epoch 24/300\n",
      "192/192 - 9s - loss: 3.4293 - accuracy: 0.6015 - val_loss: 8.4601 - val_accuracy: 0.2899\n",
      "Epoch 25/300\n",
      "192/192 - 9s - loss: 2.5298 - accuracy: 0.6616 - val_loss: 7.8764 - val_accuracy: 0.2842\n",
      "Epoch 26/300\n",
      "192/192 - 9s - loss: 2.6973 - accuracy: 0.6346 - val_loss: 8.4501 - val_accuracy: 0.2891\n",
      "Epoch 27/300\n",
      "192/192 - 9s - loss: 3.2850 - accuracy: 0.6196 - val_loss: 8.2212 - val_accuracy: 0.3021\n",
      "Epoch 28/300\n",
      "192/192 - 9s - loss: 2.6732 - accuracy: 0.6631 - val_loss: 7.3035 - val_accuracy: 0.3208\n",
      "Epoch 29/300\n",
      "192/192 - 9s - loss: 2.4908 - accuracy: 0.6693 - val_loss: 7.3642 - val_accuracy: 0.2630\n",
      "Epoch 30/300\n",
      "192/192 - 9s - loss: 2.7092 - accuracy: 0.6628 - val_loss: 9.4558 - val_accuracy: 0.2842\n",
      "Epoch 31/300\n",
      "192/192 - 9s - loss: 2.5529 - accuracy: 0.6794 - val_loss: 9.8428 - val_accuracy: 0.2182\n",
      "Epoch 32/300\n",
      "192/192 - 9s - loss: 2.6168 - accuracy: 0.6730 - val_loss: 7.8211 - val_accuracy: 0.2858\n",
      "Epoch 33/300\n",
      "192/192 - 9s - loss: 2.7380 - accuracy: 0.6820 - val_loss: 8.8347 - val_accuracy: 0.2671\n",
      "Epoch 34/300\n",
      "192/192 - 9s - loss: 2.6899 - accuracy: 0.6860 - val_loss: 8.2758 - val_accuracy: 0.3078\n",
      "Epoch 35/300\n",
      "192/192 - 9s - loss: 2.8880 - accuracy: 0.6761 - val_loss: 9.3802 - val_accuracy: 0.2826\n",
      "Epoch 36/300\n",
      "192/192 - 9s - loss: 2.3039 - accuracy: 0.7053 - val_loss: 9.4091 - val_accuracy: 0.3103\n",
      "Epoch 37/300\n",
      "192/192 - 9s - loss: 2.5113 - accuracy: 0.6929 - val_loss: 10.1685 - val_accuracy: 0.2883\n",
      "Epoch 38/300\n",
      "192/192 - 9s - loss: 3.1658 - accuracy: 0.6743 - val_loss: 9.6921 - val_accuracy: 0.2948\n",
      "Epoch 39/300\n",
      "192/192 - 9s - loss: 2.4615 - accuracy: 0.7155 - val_loss: 8.1166 - val_accuracy: 0.2899\n",
      "Epoch 40/300\n",
      "192/192 - 9s - loss: 2.1690 - accuracy: 0.7224 - val_loss: 8.0901 - val_accuracy: 0.3143\n",
      "Epoch 41/300\n",
      "192/192 - 9s - loss: 2.3556 - accuracy: 0.7158 - val_loss: 8.2174 - val_accuracy: 0.3029\n",
      "Epoch 42/300\n",
      "192/192 - 9s - loss: 2.3569 - accuracy: 0.7326 - val_loss: 9.1019 - val_accuracy: 0.3135\n",
      "Epoch 43/300\n",
      "192/192 - 9s - loss: 1.9965 - accuracy: 0.7502 - val_loss: 9.2582 - val_accuracy: 0.2744\n",
      "Epoch 44/300\n",
      "192/192 - 9s - loss: 1.9664 - accuracy: 0.7535 - val_loss: 9.3194 - val_accuracy: 0.2500\n",
      "Epoch 45/300\n",
      "192/192 - 9s - loss: 2.1811 - accuracy: 0.7421 - val_loss: 9.8863 - val_accuracy: 0.2932\n",
      "Epoch 46/300\n",
      "192/192 - 9s - loss: 1.9940 - accuracy: 0.7409 - val_loss: 8.0837 - val_accuracy: 0.3217\n",
      "Epoch 47/300\n",
      "192/192 - 9s - loss: 2.2754 - accuracy: 0.7399 - val_loss: 9.9222 - val_accuracy: 0.3160\n",
      "Epoch 48/300\n",
      "192/192 - 9s - loss: 2.4540 - accuracy: 0.7393 - val_loss: 8.1689 - val_accuracy: 0.3184\n",
      "Epoch 49/300\n",
      "192/192 - 9s - loss: 2.2646 - accuracy: 0.7456 - val_loss: 10.5627 - val_accuracy: 0.2818\n",
      "Epoch 50/300\n",
      "192/192 - 9s - loss: 2.2368 - accuracy: 0.7439 - val_loss: 11.3363 - val_accuracy: 0.2736\n",
      "Epoch 51/300\n",
      "192/192 - 9s - loss: 2.1934 - accuracy: 0.7473 - val_loss: 10.0830 - val_accuracy: 0.3160\n",
      "Epoch 52/300\n",
      "192/192 - 9s - loss: 1.8979 - accuracy: 0.7619 - val_loss: 10.2185 - val_accuracy: 0.2989\n",
      "Epoch 53/300\n",
      "192/192 - 9s - loss: 1.8808 - accuracy: 0.7720 - val_loss: 9.2170 - val_accuracy: 0.2907\n",
      "Epoch 54/300\n",
      "192/192 - 9s - loss: 2.1838 - accuracy: 0.7658 - val_loss: 10.0007 - val_accuracy: 0.3225\n",
      "Epoch 55/300\n",
      "192/192 - 9s - loss: 2.1077 - accuracy: 0.7688 - val_loss: 9.5499 - val_accuracy: 0.3037\n",
      "Epoch 56/300\n",
      "192/192 - 9s - loss: 1.9502 - accuracy: 0.7738 - val_loss: 8.4127 - val_accuracy: 0.3168\n",
      "Epoch 57/300\n",
      "192/192 - 9s - loss: 2.2124 - accuracy: 0.7660 - val_loss: 10.6729 - val_accuracy: 0.3282\n",
      "Epoch 58/300\n",
      "192/192 - 9s - loss: 1.8055 - accuracy: 0.7919 - val_loss: 9.3196 - val_accuracy: 0.3135\n",
      "Epoch 59/300\n",
      "192/192 - 9s - loss: 1.3396 - accuracy: 0.8233 - val_loss: 9.3179 - val_accuracy: 0.3192\n",
      "Epoch 60/300\n",
      "192/192 - 9s - loss: 1.5743 - accuracy: 0.8067 - val_loss: 8.1726 - val_accuracy: 0.3510\n",
      "Epoch 61/300\n",
      "192/192 - 9s - loss: 2.0036 - accuracy: 0.7662 - val_loss: 10.1507 - val_accuracy: 0.3037\n",
      "Epoch 62/300\n",
      "192/192 - 9s - loss: 2.5500 - accuracy: 0.7557 - val_loss: 10.0038 - val_accuracy: 0.3233\n",
      "Epoch 63/300\n",
      "192/192 - 9s - loss: 1.4004 - accuracy: 0.8129 - val_loss: 10.1734 - val_accuracy: 0.3249\n",
      "Epoch 64/300\n",
      "192/192 - 9s - loss: 2.2809 - accuracy: 0.7636 - val_loss: 12.1658 - val_accuracy: 0.2744\n",
      "Epoch 65/300\n",
      "192/192 - 9s - loss: 2.2141 - accuracy: 0.7735 - val_loss: 9.8502 - val_accuracy: 0.3249\n",
      "Epoch 66/300\n",
      "192/192 - 9s - loss: 2.3887 - accuracy: 0.7566 - val_loss: 11.2917 - val_accuracy: 0.3233\n",
      "Epoch 67/300\n",
      "192/192 - 9s - loss: 1.6843 - accuracy: 0.8069 - val_loss: 8.6299 - val_accuracy: 0.3697\n",
      "Epoch 68/300\n",
      "192/192 - 9s - loss: 1.2513 - accuracy: 0.8261 - val_loss: 9.4118 - val_accuracy: 0.3379\n",
      "Epoch 69/300\n",
      "192/192 - 9s - loss: 1.7279 - accuracy: 0.7966 - val_loss: 12.5007 - val_accuracy: 0.2712\n",
      "Epoch 70/300\n",
      "192/192 - 9s - loss: 2.0952 - accuracy: 0.7795 - val_loss: 9.5131 - val_accuracy: 0.3151\n",
      "Epoch 71/300\n",
      "192/192 - 9s - loss: 1.4754 - accuracy: 0.8217 - val_loss: 10.2896 - val_accuracy: 0.3257\n",
      "Epoch 72/300\n",
      "192/192 - 9s - loss: 1.6895 - accuracy: 0.8010 - val_loss: 10.1466 - val_accuracy: 0.3559\n",
      "Epoch 73/300\n",
      "192/192 - 9s - loss: 1.4391 - accuracy: 0.8207 - val_loss: 11.2755 - val_accuracy: 0.3046\n",
      "Epoch 74/300\n",
      "192/192 - 9s - loss: 1.9646 - accuracy: 0.7986 - val_loss: 10.3368 - val_accuracy: 0.3290\n",
      "Epoch 75/300\n",
      "192/192 - 9s - loss: 1.8036 - accuracy: 0.8114 - val_loss: 10.2256 - val_accuracy: 0.3436\n",
      "Epoch 76/300\n",
      "192/192 - 9s - loss: 1.5270 - accuracy: 0.8188 - val_loss: 9.1406 - val_accuracy: 0.3493\n",
      "Epoch 77/300\n",
      "192/192 - 9s - loss: 1.0609 - accuracy: 0.8580 - val_loss: 8.6061 - val_accuracy: 0.3827\n",
      "Epoch 78/300\n",
      "192/192 - 9s - loss: 1.6945 - accuracy: 0.8121 - val_loss: 11.8070 - val_accuracy: 0.3168\n",
      "Epoch 79/300\n",
      "192/192 - 9s - loss: 2.2912 - accuracy: 0.7829 - val_loss: 10.6333 - val_accuracy: 0.3567\n",
      "Epoch 80/300\n",
      "192/192 - 9s - loss: 1.7089 - accuracy: 0.8176 - val_loss: 10.5986 - val_accuracy: 0.3257\n",
      "Epoch 81/300\n",
      "192/192 - 9s - loss: 1.3606 - accuracy: 0.8385 - val_loss: 10.6584 - val_accuracy: 0.3420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "192/192 - 9s - loss: 0.9202 - accuracy: 0.8699 - val_loss: 8.8148 - val_accuracy: 0.3518\n",
      "Epoch 83/300\n",
      "192/192 - 9s - loss: 1.7093 - accuracy: 0.8228 - val_loss: 10.5806 - val_accuracy: 0.3355\n",
      "Epoch 84/300\n",
      "192/192 - 9s - loss: 2.0140 - accuracy: 0.7938 - val_loss: 10.8564 - val_accuracy: 0.3461\n",
      "Epoch 85/300\n",
      "192/192 - 9s - loss: 1.6681 - accuracy: 0.8254 - val_loss: 12.4235 - val_accuracy: 0.3453\n",
      "Epoch 86/300\n",
      "192/192 - 9s - loss: 1.9595 - accuracy: 0.7943 - val_loss: 10.1166 - val_accuracy: 0.3689\n",
      "Epoch 87/300\n",
      "192/192 - 10s - loss: 1.2138 - accuracy: 0.8549 - val_loss: 10.4367 - val_accuracy: 0.3062\n",
      "Epoch 88/300\n",
      "192/192 - 9s - loss: 1.1484 - accuracy: 0.8619 - val_loss: 10.6647 - val_accuracy: 0.3379\n",
      "Epoch 89/300\n",
      "192/192 - 9s - loss: 1.8615 - accuracy: 0.8105 - val_loss: 12.2850 - val_accuracy: 0.3200\n",
      "Epoch 90/300\n",
      "192/192 - 9s - loss: 1.7856 - accuracy: 0.8183 - val_loss: 11.3929 - val_accuracy: 0.3029\n",
      "Epoch 91/300\n",
      "192/192 - 9s - loss: 1.3475 - accuracy: 0.8479 - val_loss: 10.0439 - val_accuracy: 0.3689\n",
      "Epoch 92/300\n",
      "192/192 - 9s - loss: 1.4416 - accuracy: 0.8471 - val_loss: 12.9225 - val_accuracy: 0.3062\n",
      "Epoch 93/300\n",
      "192/192 - 9s - loss: 1.4823 - accuracy: 0.8388 - val_loss: 12.4421 - val_accuracy: 0.3192\n",
      "Epoch 94/300\n",
      "192/192 - 9s - loss: 1.7466 - accuracy: 0.8175 - val_loss: 11.5311 - val_accuracy: 0.3371\n",
      "Epoch 95/300\n",
      "192/192 - 9s - loss: 1.1142 - accuracy: 0.8679 - val_loss: 11.4897 - val_accuracy: 0.2915\n",
      "Epoch 96/300\n",
      "192/192 - 9s - loss: 1.6127 - accuracy: 0.8549 - val_loss: 11.3279 - val_accuracy: 0.3379\n",
      "Epoch 97/300\n",
      "192/192 - 9s - loss: 1.2752 - accuracy: 0.8604 - val_loss: 10.8977 - val_accuracy: 0.3436\n",
      "Epoch 98/300\n",
      "192/192 - 9s - loss: 1.3186 - accuracy: 0.8572 - val_loss: 10.1959 - val_accuracy: 0.3681\n",
      "Epoch 99/300\n",
      "192/192 - 9s - loss: 1.4360 - accuracy: 0.8385 - val_loss: 15.0769 - val_accuracy: 0.2663\n",
      "Epoch 100/300\n",
      "192/192 - 9s - loss: 1.7252 - accuracy: 0.8355 - val_loss: 10.3694 - val_accuracy: 0.3518\n",
      "Epoch 101/300\n",
      "192/192 - 9s - loss: 1.2582 - accuracy: 0.8590 - val_loss: 12.8281 - val_accuracy: 0.3176\n",
      "Epoch 102/300\n",
      "192/192 - 9s - loss: 1.7844 - accuracy: 0.8285 - val_loss: 10.6045 - val_accuracy: 0.3355\n",
      "Epoch 103/300\n",
      "192/192 - 9s - loss: 1.3323 - accuracy: 0.8557 - val_loss: 13.3391 - val_accuracy: 0.2614\n",
      "Epoch 104/300\n",
      "192/192 - 9s - loss: 0.7192 - accuracy: 0.9002 - val_loss: 10.5903 - val_accuracy: 0.3453\n",
      "Epoch 105/300\n",
      "192/192 - 9s - loss: 1.3035 - accuracy: 0.8569 - val_loss: 11.9335 - val_accuracy: 0.3290\n",
      "Epoch 106/300\n",
      "192/192 - 9s - loss: 1.3324 - accuracy: 0.8648 - val_loss: 9.9485 - val_accuracy: 0.3844\n",
      "Epoch 107/300\n",
      "192/192 - 9s - loss: 1.0026 - accuracy: 0.8852 - val_loss: 10.7693 - val_accuracy: 0.3664\n",
      "Epoch 108/300\n",
      "192/192 - 9s - loss: 1.4818 - accuracy: 0.8476 - val_loss: 12.4918 - val_accuracy: 0.3249\n",
      "Epoch 109/300\n",
      "192/192 - 9s - loss: 1.6362 - accuracy: 0.8479 - val_loss: 13.0817 - val_accuracy: 0.3094\n",
      "Epoch 110/300\n",
      "192/192 - 9s - loss: 1.2901 - accuracy: 0.8650 - val_loss: 10.6924 - val_accuracy: 0.3893\n",
      "Epoch 111/300\n",
      "192/192 - 9s - loss: 1.0858 - accuracy: 0.8891 - val_loss: 10.8245 - val_accuracy: 0.3559\n",
      "Epoch 112/300\n",
      "192/192 - 9s - loss: 1.1389 - accuracy: 0.8714 - val_loss: 11.3987 - val_accuracy: 0.3493\n",
      "Epoch 113/300\n",
      "192/192 - 9s - loss: 1.3289 - accuracy: 0.8639 - val_loss: 9.9392 - val_accuracy: 0.3893\n",
      "Epoch 114/300\n",
      "192/192 - 9s - loss: 1.0930 - accuracy: 0.8857 - val_loss: 15.1050 - val_accuracy: 0.2736\n",
      "Epoch 115/300\n",
      "192/192 - 9s - loss: 1.6838 - accuracy: 0.8547 - val_loss: 11.7664 - val_accuracy: 0.3624\n",
      "Epoch 116/300\n",
      "192/192 - 9s - loss: 1.5311 - accuracy: 0.8497 - val_loss: 11.5641 - val_accuracy: 0.3412\n",
      "Epoch 117/300\n",
      "192/192 - 9s - loss: 1.2946 - accuracy: 0.8634 - val_loss: 12.7403 - val_accuracy: 0.3225\n",
      "Epoch 118/300\n",
      "192/192 - 9s - loss: 1.2573 - accuracy: 0.8608 - val_loss: 11.6980 - val_accuracy: 0.3502\n",
      "Epoch 119/300\n",
      "192/192 - 9s - loss: 1.6000 - accuracy: 0.8508 - val_loss: 13.2694 - val_accuracy: 0.3371\n",
      "Epoch 120/300\n",
      "192/192 - 9s - loss: 1.0406 - accuracy: 0.8831 - val_loss: 13.2642 - val_accuracy: 0.3225\n",
      "Epoch 121/300\n",
      "192/192 - 9s - loss: 1.2167 - accuracy: 0.8753 - val_loss: 11.0740 - val_accuracy: 0.3836\n",
      "Epoch 122/300\n",
      "192/192 - 9s - loss: 0.8450 - accuracy: 0.8948 - val_loss: 12.4457 - val_accuracy: 0.3510\n",
      "Epoch 123/300\n",
      "192/192 - 9s - loss: 1.1603 - accuracy: 0.8709 - val_loss: 13.7365 - val_accuracy: 0.2866\n",
      "Epoch 124/300\n",
      "192/192 - 9s - loss: 1.5399 - accuracy: 0.8518 - val_loss: 13.1531 - val_accuracy: 0.3371\n",
      "Epoch 125/300\n",
      "192/192 - 9s - loss: 1.3298 - accuracy: 0.8707 - val_loss: 13.8609 - val_accuracy: 0.3420\n",
      "Epoch 126/300\n",
      "192/192 - 9s - loss: 1.2499 - accuracy: 0.8811 - val_loss: 10.7727 - val_accuracy: 0.3656\n",
      "Epoch 127/300\n",
      "192/192 - 9s - loss: 1.3675 - accuracy: 0.8751 - val_loss: 11.2605 - val_accuracy: 0.3624\n",
      "Epoch 128/300\n",
      "192/192 - 9s - loss: 1.0249 - accuracy: 0.8801 - val_loss: 13.9293 - val_accuracy: 0.3135\n",
      "Epoch 129/300\n",
      "192/192 - 9s - loss: 1.2591 - accuracy: 0.8790 - val_loss: 14.0778 - val_accuracy: 0.3037\n",
      "Epoch 130/300\n",
      "192/192 - 9s - loss: 1.5875 - accuracy: 0.8604 - val_loss: 12.1606 - val_accuracy: 0.3575\n",
      "Epoch 131/300\n",
      "192/192 - 9s - loss: 0.9696 - accuracy: 0.8865 - val_loss: 12.6293 - val_accuracy: 0.3282\n",
      "Epoch 132/300\n",
      "192/192 - 9s - loss: 0.7211 - accuracy: 0.9096 - val_loss: 12.2368 - val_accuracy: 0.3624\n",
      "Epoch 133/300\n",
      "192/192 - 9s - loss: 1.1615 - accuracy: 0.8844 - val_loss: 13.6918 - val_accuracy: 0.3241\n",
      "Epoch 134/300\n",
      "192/192 - 9s - loss: 0.8549 - accuracy: 0.9007 - val_loss: 10.7569 - val_accuracy: 0.3933\n",
      "Epoch 135/300\n",
      "192/192 - 9s - loss: 0.9131 - accuracy: 0.8945 - val_loss: 12.7785 - val_accuracy: 0.3355\n",
      "Epoch 136/300\n",
      "192/192 - 9s - loss: 1.5455 - accuracy: 0.8595 - val_loss: 15.7507 - val_accuracy: 0.2858\n",
      "Epoch 137/300\n",
      "192/192 - 9s - loss: 1.7616 - accuracy: 0.8424 - val_loss: 14.4548 - val_accuracy: 0.3078\n",
      "Epoch 138/300\n",
      "192/192 - 9s - loss: 1.0270 - accuracy: 0.9021 - val_loss: 12.2314 - val_accuracy: 0.3485\n",
      "Epoch 139/300\n",
      "192/192 - 9s - loss: 1.0452 - accuracy: 0.8896 - val_loss: 11.8921 - val_accuracy: 0.3567\n",
      "Epoch 140/300\n",
      "192/192 - 9s - loss: 1.2875 - accuracy: 0.8784 - val_loss: 11.1149 - val_accuracy: 0.3836\n",
      "Epoch 141/300\n",
      "192/192 - 9s - loss: 1.0256 - accuracy: 0.8914 - val_loss: 11.9782 - val_accuracy: 0.3477\n",
      "Epoch 142/300\n",
      "192/192 - 9s - loss: 0.6935 - accuracy: 0.9137 - val_loss: 10.3441 - val_accuracy: 0.3770\n",
      "Epoch 143/300\n",
      "192/192 - 9s - loss: 0.7457 - accuracy: 0.9187 - val_loss: 14.9202 - val_accuracy: 0.3453\n",
      "Epoch 144/300\n",
      "192/192 - 9s - loss: 1.4141 - accuracy: 0.8642 - val_loss: 14.6281 - val_accuracy: 0.3119\n",
      "Epoch 145/300\n",
      "192/192 - 9s - loss: 0.7070 - accuracy: 0.9194 - val_loss: 14.2235 - val_accuracy: 0.2964\n",
      "Epoch 146/300\n",
      "192/192 - 9s - loss: 1.6555 - accuracy: 0.8616 - val_loss: 13.4956 - val_accuracy: 0.3461\n",
      "Epoch 147/300\n",
      "192/192 - 9s - loss: 1.4593 - accuracy: 0.8665 - val_loss: 12.7134 - val_accuracy: 0.3420\n",
      "Epoch 148/300\n",
      "192/192 - 9s - loss: 1.1337 - accuracy: 0.8955 - val_loss: 12.2778 - val_accuracy: 0.3502\n",
      "Epoch 149/300\n",
      "192/192 - 9s - loss: 0.8856 - accuracy: 0.9034 - val_loss: 12.2850 - val_accuracy: 0.3559\n",
      "Epoch 150/300\n",
      "192/192 - 9s - loss: 0.7954 - accuracy: 0.9117 - val_loss: 12.8202 - val_accuracy: 0.3428\n",
      "Epoch 151/300\n",
      "192/192 - 9s - loss: 0.5525 - accuracy: 0.9310 - val_loss: 12.5089 - val_accuracy: 0.3388\n",
      "Epoch 152/300\n",
      "192/192 - 9s - loss: 1.2163 - accuracy: 0.8792 - val_loss: 12.7117 - val_accuracy: 0.3339\n",
      "Epoch 153/300\n",
      "192/192 - 9s - loss: 1.1057 - accuracy: 0.8834 - val_loss: 15.0810 - val_accuracy: 0.3135\n",
      "Epoch 154/300\n",
      "192/192 - 9s - loss: 1.3462 - accuracy: 0.8816 - val_loss: 13.9911 - val_accuracy: 0.3412\n",
      "Epoch 155/300\n",
      "192/192 - 9s - loss: 1.0751 - accuracy: 0.8889 - val_loss: 15.2775 - val_accuracy: 0.3086\n",
      "Epoch 156/300\n",
      "192/192 - 9s - loss: 1.2225 - accuracy: 0.8938 - val_loss: 13.7168 - val_accuracy: 0.3502\n",
      "Epoch 157/300\n",
      "192/192 - 9s - loss: 0.8469 - accuracy: 0.9132 - val_loss: 12.3727 - val_accuracy: 0.3770\n",
      "Epoch 158/300\n",
      "192/192 - 9s - loss: 1.2392 - accuracy: 0.8909 - val_loss: 16.1150 - val_accuracy: 0.3127\n",
      "Epoch 159/300\n",
      "192/192 - 9s - loss: 1.7756 - accuracy: 0.8608 - val_loss: 13.5897 - val_accuracy: 0.3656\n",
      "Epoch 160/300\n",
      "192/192 - 9s - loss: 0.7082 - accuracy: 0.9148 - val_loss: 12.1682 - val_accuracy: 0.3884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "192/192 - 9s - loss: 0.7107 - accuracy: 0.9213 - val_loss: 13.4807 - val_accuracy: 0.3388\n",
      "Epoch 162/300\n",
      "192/192 - 9s - loss: 1.0343 - accuracy: 0.9065 - val_loss: 13.6740 - val_accuracy: 0.3428\n",
      "Epoch 163/300\n",
      "192/192 - 9s - loss: 1.1565 - accuracy: 0.8906 - val_loss: 14.4820 - val_accuracy: 0.3518\n",
      "Epoch 164/300\n",
      "192/192 - 9s - loss: 0.6733 - accuracy: 0.9248 - val_loss: 13.6038 - val_accuracy: 0.3640\n",
      "Epoch 165/300\n",
      "192/192 - 9s - loss: 1.1127 - accuracy: 0.8922 - val_loss: 14.4603 - val_accuracy: 0.3322\n",
      "Epoch 166/300\n",
      "192/192 - 9s - loss: 0.9949 - accuracy: 0.8994 - val_loss: 13.5641 - val_accuracy: 0.3339\n",
      "Epoch 167/300\n",
      "192/192 - 9s - loss: 0.8004 - accuracy: 0.9171 - val_loss: 13.0063 - val_accuracy: 0.3681\n",
      "Epoch 168/300\n",
      "192/192 - 9s - loss: 0.8265 - accuracy: 0.9051 - val_loss: 12.3705 - val_accuracy: 0.3770\n",
      "Epoch 169/300\n",
      "192/192 - 9s - loss: 0.4807 - accuracy: 0.9373 - val_loss: 11.9566 - val_accuracy: 0.4145\n",
      "Epoch 170/300\n",
      "192/192 - 9s - loss: 1.0511 - accuracy: 0.9026 - val_loss: 15.2754 - val_accuracy: 0.3168\n",
      "Epoch 171/300\n",
      "192/192 - 9s - loss: 1.3921 - accuracy: 0.8867 - val_loss: 15.8079 - val_accuracy: 0.3208\n",
      "Epoch 172/300\n",
      "192/192 - 9s - loss: 1.3851 - accuracy: 0.8798 - val_loss: 14.1416 - val_accuracy: 0.3534\n",
      "Epoch 173/300\n",
      "192/192 - 9s - loss: 0.5956 - accuracy: 0.9319 - val_loss: 12.7047 - val_accuracy: 0.3779\n",
      "Epoch 174/300\n",
      "192/192 - 9s - loss: 0.6532 - accuracy: 0.9243 - val_loss: 14.2731 - val_accuracy: 0.3322\n",
      "Epoch 175/300\n",
      "192/192 - 9s - loss: 0.9371 - accuracy: 0.9124 - val_loss: 17.1459 - val_accuracy: 0.2989\n",
      "Epoch 176/300\n",
      "192/192 - 9s - loss: 1.7336 - accuracy: 0.8645 - val_loss: 15.3348 - val_accuracy: 0.3208\n",
      "Epoch 177/300\n",
      "192/192 - 9s - loss: 0.7198 - accuracy: 0.9145 - val_loss: 13.0320 - val_accuracy: 0.3705\n",
      "Epoch 178/300\n",
      "192/192 - 9s - loss: 0.8423 - accuracy: 0.9132 - val_loss: 12.0443 - val_accuracy: 0.3941\n",
      "Epoch 179/300\n",
      "192/192 - 9s - loss: 0.7437 - accuracy: 0.9199 - val_loss: 12.6715 - val_accuracy: 0.3901\n",
      "Epoch 180/300\n",
      "192/192 - 9s - loss: 0.9478 - accuracy: 0.9052 - val_loss: 15.3431 - val_accuracy: 0.3355\n",
      "Epoch 181/300\n",
      "192/192 - 9s - loss: 0.9048 - accuracy: 0.9152 - val_loss: 13.8287 - val_accuracy: 0.3534\n",
      "Epoch 182/300\n",
      "192/192 - 9s - loss: 0.6216 - accuracy: 0.9275 - val_loss: 13.1781 - val_accuracy: 0.3852\n",
      "Epoch 183/300\n",
      "192/192 - 9s - loss: 0.7186 - accuracy: 0.9222 - val_loss: 14.5397 - val_accuracy: 0.3575\n",
      "Epoch 184/300\n",
      "192/192 - 9s - loss: 1.2178 - accuracy: 0.8938 - val_loss: 14.5509 - val_accuracy: 0.3493\n",
      "Epoch 185/300\n",
      "192/192 - 9s - loss: 0.9148 - accuracy: 0.9150 - val_loss: 16.0327 - val_accuracy: 0.3331\n",
      "Epoch 186/300\n",
      "192/192 - 9s - loss: 1.5366 - accuracy: 0.8855 - val_loss: 14.0961 - val_accuracy: 0.3640\n",
      "Epoch 187/300\n",
      "192/192 - 9s - loss: 0.9900 - accuracy: 0.9056 - val_loss: 14.9133 - val_accuracy: 0.3844\n",
      "Epoch 188/300\n",
      "192/192 - 9s - loss: 0.8344 - accuracy: 0.9165 - val_loss: 15.2685 - val_accuracy: 0.3412\n",
      "Epoch 189/300\n",
      "192/192 - 9s - loss: 1.0197 - accuracy: 0.9005 - val_loss: 15.6355 - val_accuracy: 0.3379\n",
      "Epoch 190/300\n",
      "192/192 - 9s - loss: 0.9001 - accuracy: 0.9106 - val_loss: 13.6981 - val_accuracy: 0.3738\n",
      "Epoch 191/300\n",
      "192/192 - 9s - loss: 0.6607 - accuracy: 0.9358 - val_loss: 15.2279 - val_accuracy: 0.3567\n",
      "Epoch 192/300\n",
      "192/192 - 9s - loss: 0.8783 - accuracy: 0.9139 - val_loss: 13.4953 - val_accuracy: 0.3803\n",
      "Epoch 193/300\n",
      "192/192 - 9s - loss: 0.7562 - accuracy: 0.9187 - val_loss: 15.1690 - val_accuracy: 0.3616\n",
      "Epoch 194/300\n",
      "192/192 - 9s - loss: 1.2648 - accuracy: 0.8959 - val_loss: 15.5746 - val_accuracy: 0.3396\n",
      "Epoch 195/300\n",
      "192/192 - 9s - loss: 0.5051 - accuracy: 0.9420 - val_loss: 13.6554 - val_accuracy: 0.3811\n",
      "Epoch 196/300\n",
      "192/192 - 9s - loss: 0.9674 - accuracy: 0.9091 - val_loss: 14.7426 - val_accuracy: 0.3721\n",
      "Epoch 197/300\n",
      "192/192 - 9s - loss: 0.8670 - accuracy: 0.9145 - val_loss: 16.3869 - val_accuracy: 0.3379\n",
      "Epoch 198/300\n",
      "192/192 - 9s - loss: 0.6999 - accuracy: 0.9261 - val_loss: 13.1027 - val_accuracy: 0.3779\n",
      "Epoch 199/300\n",
      "192/192 - 9s - loss: 0.6793 - accuracy: 0.9274 - val_loss: 14.7869 - val_accuracy: 0.3664\n",
      "Epoch 200/300\n",
      "192/192 - 9s - loss: 0.9978 - accuracy: 0.9103 - val_loss: 15.6121 - val_accuracy: 0.3282\n",
      "Epoch 201/300\n",
      "192/192 - 9s - loss: 1.1307 - accuracy: 0.9020 - val_loss: 17.9589 - val_accuracy: 0.3225\n",
      "Epoch 202/300\n",
      "192/192 - 9s - loss: 1.2400 - accuracy: 0.8968 - val_loss: 16.4054 - val_accuracy: 0.3298\n",
      "Epoch 203/300\n",
      "192/192 - 9s - loss: 0.7176 - accuracy: 0.9236 - val_loss: 14.1227 - val_accuracy: 0.3616\n",
      "Epoch 204/300\n",
      "192/192 - 9s - loss: 0.6056 - accuracy: 0.9350 - val_loss: 13.5924 - val_accuracy: 0.3721\n",
      "Epoch 205/300\n",
      "192/192 - 9s - loss: 0.6331 - accuracy: 0.9292 - val_loss: 16.1630 - val_accuracy: 0.3420\n",
      "Epoch 206/300\n",
      "192/192 - 9s - loss: 1.0386 - accuracy: 0.9207 - val_loss: 14.4587 - val_accuracy: 0.3795\n",
      "Epoch 207/300\n",
      "192/192 - 9s - loss: 1.2158 - accuracy: 0.9078 - val_loss: 14.4557 - val_accuracy: 0.3485\n",
      "Epoch 208/300\n",
      "192/192 - 9s - loss: 0.9763 - accuracy: 0.9109 - val_loss: 14.5788 - val_accuracy: 0.3868\n",
      "Epoch 209/300\n",
      "192/192 - 9s - loss: 0.7690 - accuracy: 0.9241 - val_loss: 13.7575 - val_accuracy: 0.3819\n",
      "Epoch 210/300\n",
      "192/192 - 9s - loss: 0.6520 - accuracy: 0.9327 - val_loss: 13.3904 - val_accuracy: 0.3803\n",
      "Epoch 211/300\n",
      "192/192 - 9s - loss: 0.7656 - accuracy: 0.9305 - val_loss: 16.4224 - val_accuracy: 0.3648\n",
      "Epoch 212/300\n",
      "192/192 - 9s - loss: 1.2200 - accuracy: 0.9020 - val_loss: 14.9797 - val_accuracy: 0.3591\n",
      "Epoch 213/300\n",
      "192/192 - 9s - loss: 0.6559 - accuracy: 0.9244 - val_loss: 14.2007 - val_accuracy: 0.3860\n",
      "Epoch 214/300\n",
      "192/192 - 9s - loss: 0.8216 - accuracy: 0.9210 - val_loss: 13.7289 - val_accuracy: 0.3787\n",
      "Epoch 215/300\n",
      "192/192 - 9s - loss: 0.9849 - accuracy: 0.9104 - val_loss: 14.7054 - val_accuracy: 0.3681\n",
      "Epoch 216/300\n",
      "192/192 - 9s - loss: 0.7366 - accuracy: 0.9274 - val_loss: 15.5433 - val_accuracy: 0.3347\n",
      "Epoch 217/300\n",
      "192/192 - 9s - loss: 0.5081 - accuracy: 0.9463 - val_loss: 13.5157 - val_accuracy: 0.3909\n",
      "Epoch 218/300\n",
      "192/192 - 9s - loss: 0.6114 - accuracy: 0.9415 - val_loss: 14.9477 - val_accuracy: 0.3770\n",
      "Epoch 219/300\n",
      "192/192 - 9s - loss: 1.2495 - accuracy: 0.8937 - val_loss: 16.7642 - val_accuracy: 0.3265\n",
      "Epoch 220/300\n",
      "192/192 - 9s - loss: 1.5966 - accuracy: 0.8787 - val_loss: 17.6422 - val_accuracy: 0.3412\n",
      "Epoch 221/300\n",
      "192/192 - 9s - loss: 0.8059 - accuracy: 0.9287 - val_loss: 16.0217 - val_accuracy: 0.3673\n",
      "Epoch 222/300\n",
      "192/192 - 9s - loss: 0.8151 - accuracy: 0.9220 - val_loss: 14.3528 - val_accuracy: 0.3836\n",
      "Epoch 223/300\n",
      "192/192 - 9s - loss: 0.3604 - accuracy: 0.9560 - val_loss: 13.7715 - val_accuracy: 0.3925\n",
      "Epoch 224/300\n",
      "192/192 - 9s - loss: 0.6625 - accuracy: 0.9277 - val_loss: 15.2895 - val_accuracy: 0.3901\n",
      "Epoch 225/300\n",
      "192/192 - 9s - loss: 1.3236 - accuracy: 0.8912 - val_loss: 15.7766 - val_accuracy: 0.3404\n",
      "Epoch 226/300\n",
      "192/192 - 9s - loss: 0.6261 - accuracy: 0.9388 - val_loss: 14.7280 - val_accuracy: 0.3697\n",
      "Epoch 227/300\n",
      "192/192 - 9s - loss: 0.5788 - accuracy: 0.9368 - val_loss: 13.2296 - val_accuracy: 0.3982\n",
      "Epoch 228/300\n",
      "192/192 - 9s - loss: 0.5551 - accuracy: 0.9466 - val_loss: 14.8734 - val_accuracy: 0.3681\n",
      "Epoch 229/300\n",
      "192/192 - 9s - loss: 1.4598 - accuracy: 0.8972 - val_loss: 17.2204 - val_accuracy: 0.3290\n",
      "Epoch 230/300\n",
      "192/192 - 9s - loss: 0.7252 - accuracy: 0.9264 - val_loss: 14.8269 - val_accuracy: 0.3730\n",
      "Epoch 231/300\n",
      "192/192 - 9s - loss: 0.4485 - accuracy: 0.9505 - val_loss: 14.2444 - val_accuracy: 0.3705\n",
      "Epoch 232/300\n",
      "192/192 - 9s - loss: 0.8940 - accuracy: 0.9259 - val_loss: 15.2463 - val_accuracy: 0.3990\n",
      "Epoch 233/300\n",
      "192/192 - 9s - loss: 1.1143 - accuracy: 0.9043 - val_loss: 17.8506 - val_accuracy: 0.2940\n",
      "Epoch 234/300\n",
      "192/192 - 9s - loss: 1.2931 - accuracy: 0.8886 - val_loss: 14.1227 - val_accuracy: 0.3705\n",
      "Epoch 235/300\n",
      "192/192 - 9s - loss: 0.5474 - accuracy: 0.9448 - val_loss: 13.6943 - val_accuracy: 0.4023\n",
      "Epoch 236/300\n",
      "192/192 - 9s - loss: 0.5979 - accuracy: 0.9412 - val_loss: 15.1702 - val_accuracy: 0.3428\n",
      "Epoch 237/300\n",
      "192/192 - 9s - loss: 0.5856 - accuracy: 0.9427 - val_loss: 16.4935 - val_accuracy: 0.3355\n",
      "Epoch 238/300\n",
      "192/192 - 9s - loss: 0.6281 - accuracy: 0.9388 - val_loss: 13.3468 - val_accuracy: 0.4137\n",
      "Epoch 239/300\n",
      "192/192 - 9s - loss: 0.4279 - accuracy: 0.9503 - val_loss: 15.0218 - val_accuracy: 0.3754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "192/192 - 9s - loss: 0.7976 - accuracy: 0.9342 - val_loss: 18.8134 - val_accuracy: 0.3184\n",
      "Epoch 241/300\n",
      "192/192 - 9s - loss: 1.8359 - accuracy: 0.8823 - val_loss: 17.2084 - val_accuracy: 0.3632\n",
      "Epoch 242/300\n",
      "192/192 - 9s - loss: 0.9404 - accuracy: 0.9257 - val_loss: 16.1635 - val_accuracy: 0.3762\n",
      "Epoch 243/300\n",
      "192/192 - 9s - loss: 0.8201 - accuracy: 0.9293 - val_loss: 14.9663 - val_accuracy: 0.3616\n",
      "Epoch 244/300\n",
      "192/192 - 9s - loss: 0.5224 - accuracy: 0.9433 - val_loss: 14.5833 - val_accuracy: 0.3827\n",
      "Epoch 245/300\n",
      "192/192 - 9s - loss: 0.4690 - accuracy: 0.9575 - val_loss: 17.3520 - val_accuracy: 0.3412\n",
      "Epoch 246/300\n",
      "192/192 - 9s - loss: 0.5953 - accuracy: 0.9391 - val_loss: 14.8012 - val_accuracy: 0.3648\n",
      "Epoch 247/300\n",
      "192/192 - 9s - loss: 0.4731 - accuracy: 0.9469 - val_loss: 15.3221 - val_accuracy: 0.3762\n",
      "Epoch 248/300\n",
      "192/192 - 9s - loss: 0.9568 - accuracy: 0.9284 - val_loss: 15.6635 - val_accuracy: 0.3632\n",
      "Epoch 249/300\n",
      "192/192 - 9s - loss: 0.6372 - accuracy: 0.9331 - val_loss: 17.0611 - val_accuracy: 0.3388\n",
      "Epoch 250/300\n",
      "192/192 - 9s - loss: 0.5355 - accuracy: 0.9412 - val_loss: 16.7370 - val_accuracy: 0.3632\n",
      "Epoch 251/300\n",
      "192/192 - 9s - loss: 1.3540 - accuracy: 0.8997 - val_loss: 19.3027 - val_accuracy: 0.3396\n",
      "Epoch 252/300\n",
      "192/192 - 9s - loss: 0.7008 - accuracy: 0.9350 - val_loss: 15.6082 - val_accuracy: 0.3664\n",
      "Epoch 253/300\n",
      "192/192 - 9s - loss: 0.6126 - accuracy: 0.9420 - val_loss: 14.5428 - val_accuracy: 0.3884\n",
      "Epoch 254/300\n",
      "192/192 - 9s - loss: 1.4035 - accuracy: 0.9099 - val_loss: 18.1810 - val_accuracy: 0.3428\n",
      "Epoch 255/300\n",
      "192/192 - 9s - loss: 0.5496 - accuracy: 0.9459 - val_loss: 14.4288 - val_accuracy: 0.3958\n",
      "Epoch 256/300\n",
      "192/192 - 9s - loss: 0.2646 - accuracy: 0.9678 - val_loss: 15.5078 - val_accuracy: 0.3697\n",
      "Epoch 257/300\n",
      "192/192 - 9s - loss: 0.2168 - accuracy: 0.9749 - val_loss: 13.9770 - val_accuracy: 0.4072\n",
      "Epoch 258/300\n",
      "192/192 - 9s - loss: 0.2881 - accuracy: 0.9694 - val_loss: 14.4239 - val_accuracy: 0.4055\n",
      "Epoch 259/300\n",
      "192/192 - 9s - loss: 0.7919 - accuracy: 0.9376 - val_loss: 15.3967 - val_accuracy: 0.3811\n",
      "Epoch 260/300\n",
      "192/192 - 9s - loss: 1.1819 - accuracy: 0.9205 - val_loss: 17.2158 - val_accuracy: 0.3290\n",
      "Epoch 261/300\n",
      "192/192 - 9s - loss: 1.2811 - accuracy: 0.9064 - val_loss: 17.8710 - val_accuracy: 0.3436\n",
      "Epoch 262/300\n",
      "192/192 - 9s - loss: 1.0599 - accuracy: 0.9176 - val_loss: 17.2321 - val_accuracy: 0.3656\n",
      "Epoch 263/300\n",
      "192/192 - 9s - loss: 0.8172 - accuracy: 0.9266 - val_loss: 15.2498 - val_accuracy: 0.3917\n",
      "Epoch 264/300\n",
      "192/192 - 9s - loss: 0.5985 - accuracy: 0.9458 - val_loss: 14.1784 - val_accuracy: 0.3982\n",
      "Epoch 265/300\n",
      "192/192 - 9s - loss: 0.2872 - accuracy: 0.9699 - val_loss: 16.7373 - val_accuracy: 0.3599\n",
      "Epoch 266/300\n",
      "192/192 - 9s - loss: 0.9212 - accuracy: 0.9310 - val_loss: 15.4440 - val_accuracy: 0.3982\n",
      "Epoch 267/300\n",
      "192/192 - 9s - loss: 0.7934 - accuracy: 0.9261 - val_loss: 15.5874 - val_accuracy: 0.3852\n",
      "Epoch 268/300\n",
      "192/192 - 9s - loss: 0.7245 - accuracy: 0.9339 - val_loss: 16.7549 - val_accuracy: 0.3575\n",
      "Epoch 269/300\n",
      "192/192 - 9s - loss: 0.5437 - accuracy: 0.9453 - val_loss: 16.8960 - val_accuracy: 0.3550\n",
      "Epoch 270/300\n",
      "192/192 - 9s - loss: 0.5546 - accuracy: 0.9502 - val_loss: 15.8244 - val_accuracy: 0.3673\n",
      "Epoch 271/300\n",
      "192/192 - 9s - loss: 0.7789 - accuracy: 0.9311 - val_loss: 16.0520 - val_accuracy: 0.3787\n",
      "Epoch 272/300\n",
      "192/192 - 9s - loss: 0.4773 - accuracy: 0.9557 - val_loss: 14.2046 - val_accuracy: 0.3901\n",
      "Epoch 273/300\n",
      "192/192 - 9s - loss: 0.6674 - accuracy: 0.9391 - val_loss: 16.5641 - val_accuracy: 0.3656\n",
      "Epoch 274/300\n",
      "192/192 - 9s - loss: 1.3631 - accuracy: 0.8990 - val_loss: 20.5847 - val_accuracy: 0.3265\n",
      "Epoch 275/300\n",
      "192/192 - 9s - loss: 0.6969 - accuracy: 0.9376 - val_loss: 15.0243 - val_accuracy: 0.4072\n",
      "Epoch 276/300\n",
      "192/192 - 9s - loss: 0.2248 - accuracy: 0.9754 - val_loss: 14.9094 - val_accuracy: 0.4055\n",
      "Epoch 277/300\n",
      "192/192 - 9s - loss: 0.6606 - accuracy: 0.9401 - val_loss: 17.0616 - val_accuracy: 0.3624\n",
      "Epoch 278/300\n",
      "192/192 - 9s - loss: 0.8796 - accuracy: 0.9288 - val_loss: 16.2311 - val_accuracy: 0.3811\n",
      "Epoch 279/300\n",
      "192/192 - 9s - loss: 0.5915 - accuracy: 0.9437 - val_loss: 16.0264 - val_accuracy: 0.3844\n",
      "Epoch 280/300\n",
      "192/192 - 9s - loss: 0.9662 - accuracy: 0.9161 - val_loss: 19.1580 - val_accuracy: 0.3331\n",
      "Epoch 281/300\n",
      "192/192 - 9s - loss: 0.6021 - accuracy: 0.9381 - val_loss: 18.5558 - val_accuracy: 0.3265\n",
      "Epoch 282/300\n",
      "192/192 - 9s - loss: 0.7695 - accuracy: 0.9397 - val_loss: 15.8569 - val_accuracy: 0.3876\n",
      "Epoch 283/300\n",
      "192/192 - 9s - loss: 0.5479 - accuracy: 0.9585 - val_loss: 16.0485 - val_accuracy: 0.3836\n",
      "Epoch 284/300\n",
      "192/192 - 9s - loss: 0.4055 - accuracy: 0.9582 - val_loss: 17.2813 - val_accuracy: 0.3485\n",
      "Epoch 285/300\n",
      "192/192 - 9s - loss: 0.7608 - accuracy: 0.9326 - val_loss: 16.2553 - val_accuracy: 0.3713\n",
      "Epoch 286/300\n",
      "192/192 - 9s - loss: 0.3419 - accuracy: 0.9616 - val_loss: 14.3297 - val_accuracy: 0.4080\n",
      "Epoch 287/300\n",
      "192/192 - 9s - loss: 1.4590 - accuracy: 0.9126 - val_loss: 18.7802 - val_accuracy: 0.3363\n",
      "Epoch 288/300\n",
      "192/192 - 9s - loss: 0.8602 - accuracy: 0.9270 - val_loss: 17.8417 - val_accuracy: 0.3738\n",
      "Epoch 289/300\n",
      "192/192 - 9s - loss: 0.6021 - accuracy: 0.9419 - val_loss: 14.7133 - val_accuracy: 0.4186\n",
      "Epoch 290/300\n",
      "192/192 - 9s - loss: 0.3345 - accuracy: 0.9637 - val_loss: 15.1751 - val_accuracy: 0.4007\n",
      "Epoch 291/300\n",
      "192/192 - 9s - loss: 0.7683 - accuracy: 0.9425 - val_loss: 17.4670 - val_accuracy: 0.3827\n",
      "Epoch 292/300\n",
      "192/192 - 9s - loss: 1.0361 - accuracy: 0.9197 - val_loss: 17.6663 - val_accuracy: 0.3713\n",
      "Epoch 293/300\n",
      "192/192 - 9s - loss: 1.0375 - accuracy: 0.9218 - val_loss: 16.6133 - val_accuracy: 0.3803\n",
      "Epoch 294/300\n",
      "192/192 - 9s - loss: 0.4548 - accuracy: 0.9513 - val_loss: 15.7811 - val_accuracy: 0.3836\n",
      "Epoch 295/300\n",
      "192/192 - 9s - loss: 0.6153 - accuracy: 0.9445 - val_loss: 16.4919 - val_accuracy: 0.3624\n",
      "Epoch 296/300\n",
      "192/192 - 9s - loss: 0.4264 - accuracy: 0.9593 - val_loss: 15.4787 - val_accuracy: 0.3852\n",
      "Epoch 297/300\n",
      "192/192 - 9s - loss: 0.6821 - accuracy: 0.9435 - val_loss: 15.9237 - val_accuracy: 0.3868\n",
      "Epoch 298/300\n",
      "192/192 - 9s - loss: 0.5439 - accuracy: 0.9549 - val_loss: 15.3439 - val_accuracy: 0.4064\n",
      "Epoch 299/300\n",
      "192/192 - 9s - loss: 0.3478 - accuracy: 0.9653 - val_loss: 14.9027 - val_accuracy: 0.3901\n",
      "Epoch 300/300\n",
      "192/192 - 9s - loss: 1.4574 - accuracy: 0.9091 - val_loss: 20.4358 - val_accuracy: 0.3388\n",
      "26/26 - 1s - loss: 20.6087 - accuracy: 0.3293\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"transfer-learning-tests\"\n",
    "RUN_NAME = \"resnet_fifty\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_tracking_uri('file:///E:/GoogleSync/Masters/Dissertation/MLflow/mlruns')\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        \n",
    "        mlflow.tensorflow.autolog()\n",
    "        \n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2799b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7b9e147",
   "metadata": {},
   "source": [
    "# ResNet 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31448adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961a01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297650e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d8667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b559b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f115d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83a754a",
   "metadata": {},
   "source": [
    "# Experiment InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1364a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model without output layer\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "59a01fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.InceptionV3(include_top = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "704716c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 149, 149, 32) 96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 149, 149, 32) 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 147, 147, 32) 9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 147, 147, 32) 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 147, 147, 32) 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 147, 147, 64) 18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 147, 147, 64) 192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 147, 147, 64) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 73, 73, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 73, 73, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 73, 73, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 71, 71, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 71, 71, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 71, 71, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 35, 35, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 35, 35, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 35, 35, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 35, 35, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 35, 35, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 35, 35, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 35, 35, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 35, 35, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 35, 35, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 35, 35, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 35, 35, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 35, 35, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 35, 35, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 35, 35, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 35, 35, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 35, 35, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 35, 35, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 35, 35, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 35, 35, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 35, 35, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 35, 35, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 35, 35, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 35, 35, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 35, 35, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 35, 35, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 35, 35, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 35, 35, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 35, 35, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 35, 35, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 35, 35, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 35, 35, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 35, 35, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 35, 35, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 35, 35, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 35, 35, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 35, 35, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 35, 35, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 35, 35, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 35, 35, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 35, 35, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 35, 35, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 35, 35, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 35, 35, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 35, 35, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 35, 35, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 35, 35, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 35, 35, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 35, 35, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 35, 35, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 35, 35, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 35, 35, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 35, 35, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 35, 35, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 35, 35, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 35, 35, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 35, 35, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 35, 35, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 17, 17, 96)   82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 17, 17, 384)  1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 17, 17, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 17, 17, 384)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 17, 17, 96)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 17, 17, 128)  384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 17, 17, 128)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 17, 17, 128)  114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 17, 17, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 17, 17, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 17, 17, 128)  114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 17, 17, 128)  384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 17, 17, 128)  384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 17, 17, 128)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 17, 17, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 17, 17, 128)  114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 17, 17, 128)  114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 17, 17, 128)  384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 17, 17, 128)  384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 17, 17, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 17, 17, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 17, 17, 192)  172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 17, 17, 192)  172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 17, 17, 192)  576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 17, 17, 192)  576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 17, 17, 192)  576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 17, 17, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 17, 17, 192)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 17, 17, 192)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 17, 17, 192)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 17, 17, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 17, 17, 160)  480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 17, 17, 160)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 17, 17, 160)  179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 17, 17, 160)  480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 17, 17, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 17, 17, 160)  179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 17, 17, 160)  480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 17, 17, 160)  480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 17, 17, 160)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 17, 17, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 17, 17, 160)  179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 17, 17, 160)  179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 17, 17, 160)  480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 17, 17, 160)  480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 17, 17, 160)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 17, 17, 160)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 17, 17, 192)  215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 17, 17, 192)  215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 17, 17, 192)  576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 17, 17, 192)  576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 17, 17, 192)  576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 17, 17, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 17, 17, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 17, 17, 192)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 17, 17, 192)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 17, 17, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 17, 17, 160)  480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 17, 17, 160)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 17, 17, 160)  179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 17, 17, 160)  480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 17, 17, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 17, 17, 160)  179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 17, 17, 160)  480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 17, 17, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 17, 17, 160)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 17, 17, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 17, 17, 160)  179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 17, 17, 160)  179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 17, 17, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 17, 17, 160)  480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 17, 17, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 17, 17, 160)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 17, 17, 192)  215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 17, 17, 192)  215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 17, 17, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 17, 17, 192)  576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 17, 17, 192)  576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 17, 17, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 17, 17, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 17, 17, 192)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 17, 17, 192)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 17, 17, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 17, 17, 192)  576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 17, 17, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 17, 17, 192)  258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 17, 17, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 17, 17, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 17, 17, 192)  258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 17, 17, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 17, 17, 192)  576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 17, 17, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 17, 17, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 17, 17, 192)  258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 17, 17, 192)  258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 17, 17, 192)  576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 17, 17, 192)  576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 17, 17, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 17, 17, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 17, 17, 192)  258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 17, 17, 192)  258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 17, 17, 192)  576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 17, 17, 192)  576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 17, 17, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 17, 17, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 17, 17, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 17, 17, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 17, 17, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 17, 17, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 17, 17, 192)  576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 17, 17, 192)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 17, 17, 192)  258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 17, 17, 192)  576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 17, 17, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 17, 17, 192)  258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 17, 17, 192)  576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 17, 17, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 17, 17, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 17, 17, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 8, 8, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 8, 8, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 8, 8, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 8, 8, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 8, 8, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 8, 8, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 8, 8, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 8, 8, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 8, 8, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 8, 8, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 8, 8, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 8, 8, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 8, 8, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 8, 8, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 8, 8, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 8, 8, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 8, 8, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 8, 8, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 8, 8, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 8, 8, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 8, 8, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 8, 8, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 8, 8, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 8, 8, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bb928e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_inputs = model.layers[0].input\n",
    "base_outputs = model.layers[-2].output\n",
    "final_outputs = layers.Dense(102)(base_outputs)\n",
    "model = keras.Model(inputs=base_inputs, outputs=final_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6f28e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63b90d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Total params: 22,011,782\n",
      "Trainable params: 21,977,350\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f79c05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/08/14 19:28:38 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... 'input_4_ib-0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... 'input_4_ib-0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "192/192 - 58s - loss: 9.5431 - accuracy: 0.0135 - val_loss: 10.9589 - val_accuracy: 0.0179\n",
      "Epoch 2/300\n",
      "192/192 - 35s - loss: 6.8953 - accuracy: 0.0202 - val_loss: 5.2371 - val_accuracy: 0.0179\n",
      "Epoch 3/300\n",
      "192/192 - 35s - loss: 5.2100 - accuracy: 0.0202 - val_loss: 5.2371 - val_accuracy: 0.0179\n",
      "Epoch 4/300\n",
      "192/192 - 35s - loss: 5.2100 - accuracy: 0.0202 - val_loss: 5.2371 - val_accuracy: 0.0179\n",
      "Epoch 5/300\n",
      "192/192 - 34s - loss: 5.2100 - accuracy: 0.0202 - val_loss: 5.2371 - val_accuracy: 0.0179\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-7153b1a39173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautolog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1161\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    276\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    296\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    339\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    501\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"transfer-learning-tests\"\n",
    "RUN_NAME = \"inception_v_three\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_tracking_uri('file:///E:/GoogleSync/Masters/Dissertation/MLflow/mlruns')\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        \n",
    "        mlflow.tensorflow.autolog()\n",
    "        \n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef45304",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415849de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aadfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images 224*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 300\n",
    "verbose= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26923e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"transfer-learning-tests\"\n",
    "RUN_NAME = \"vgg_one_six\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_tracking_uri('file:///E:/GoogleSync/Masters/Dissertation/MLflow/mlruns')\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        \n",
    "        mlflow.tensorflow.autolog()\n",
    "        \n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b19993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "676014d1",
   "metadata": {},
   "source": [
    "# VGG 19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdac88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4144b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d578f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ea2a104",
   "metadata": {},
   "source": [
    "# Mobilenet v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "634a3ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\yisi9\\AppData\\Local\\Temp\\tfhub_modules\\145bb06ec3b59b08fb564ab752bd5aa222bfb50a\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-68cf484780e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create a Feature Extractor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m feature_extractor = hub.KerasLayer(URL,\n\u001b[0m\u001b[0;32m      6\u001b[0m                                    input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Freeze the Pre-Trained Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf3080\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_is_hub_module_v1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf3080\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Expected before TF2.4.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mset_load_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf3080\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   \"\"\"\n\u001b[1;32m--> 869\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    879\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m   saved_model_proto, debug_info = (\n\u001b[1;32m--> 881\u001b[1;33m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m   \"\"\"\n\u001b[1;32m---> 56\u001b[1;33m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m   debug_info_path = os.path.join(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\yisi9\\AppData\\Local\\Temp\\tfhub_modules\\145bb06ec3b59b08fb564ab752bd5aa222bfb50a\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# TODO: Build and train your network.\n",
    "from tensorflow.keras import layers\n",
    "# Create a Feature Extractor\n",
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "feature_extractor = hub.KerasLayer(URL,\n",
    "                                   input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# Freeze the Pre-Trained Model\n",
    "feature_extractor.trainable = False\n",
    "# Attach a classification head\n",
    "model = tf.keras.Sequential([\n",
    "  feature_extractor,\n",
    "  layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "verbose= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"transfer-learning-tests\"\n",
    "RUN_NAME = \"mobilenet_V_two\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.set_tracking_uri('file:///E:/GoogleSync/Masters/Dissertation/MLflow/mlruns')\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        \n",
    "        mlflow.tensorflow.autolog()\n",
    "        \n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = verbose)\n",
    "        \n",
    "        mlflow.log_param(\"activation function\", act)\n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bdc68",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443337a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44917ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ca2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ff66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8e38d28",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e7757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584de625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
