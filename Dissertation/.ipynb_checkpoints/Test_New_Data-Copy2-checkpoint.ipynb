{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "351ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "###imports###\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy import io\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import logging\n",
    "#import skimage.io\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from keras.models import Model\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9d145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "NUM_CLASSES = 102\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e731521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c7ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.preprocessing.image.ImageDataGenerator"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a48cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataset_dir = 'E:/Github/thesis/flowerDataset/Flower/'\n",
    "labels_dir = 'E:/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "new_flower_dataset_dir = 'E:/Github/thesis/flowerDataset/new_flower_dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e13df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = io.loadmat(labels_dir)\n",
    "data_labels = data_labels.items()\n",
    "data_labels = list(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0d6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ff0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1][3][0] #loads the labels that is stored in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eea6b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcea27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = pd.DataFrame(dict(file_name=os.listdir(orig_dataset_dir),labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cc47861",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8da6459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_test = train_test_split(image_data, test_size=1 - train_ratio, random_state=11, stratify=image_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12862e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_val, image_test = train_test_split(image_data, test_size=1 - train_ratio, random_state=11, stratify=image_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eacafdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>image_01187.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>image_03775.jpg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>image_04293.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>image_02403.jpg</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>image_06854.jpg</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>image_06383.jpg</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>image_07198.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>image_00133.jpg</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5491</th>\n",
       "      <td>image_05492.jpg</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>image_03787.jpg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name  labels\n",
       "1186  image_01187.jpg      74\n",
       "3774  image_03775.jpg      37\n",
       "4292  image_04293.jpg      18\n",
       "2402  image_02403.jpg      43\n",
       "6853  image_06854.jpg      27\n",
       "...               ...     ...\n",
       "6382  image_06383.jpg      15\n",
       "7197  image_07198.jpg       6\n",
       "132   image_00133.jpg      77\n",
       "5491  image_05492.jpg      87\n",
       "3786  image_03787.jpg      37\n",
       "\n",
       "[2048 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bcad9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flower_dataset_dir = \"E:/Github/thesis/flowerDataset/new_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1f413c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in image_test.to_dict(orient='records'):\n",
    "    new_dir = new_flower_dataset_dir+'test/'+str(_['labels'])\n",
    "    if os.path.isdir(new_dir): #check if director exist the copy file\n",
    "        shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    else: #create folder with name label and copy over file \n",
    "        os.makedirs(new_dir)\n",
    "        shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d86b1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in image_train.to_dict(orient='records'):\n",
    "    new_dir = new_flower_dataset_dir+'train/'+str(_['labels'])\n",
    "    if os.path.isdir(new_dir): #check if director exist the copy file\n",
    "        shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    else: #create folder with name label and copy over file \n",
    "        os.makedirs(new_dir)\n",
    "        shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f756b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in image_val.to_dict(orient='records'):\n",
    "    new_dir = new_flower_dataset_dir+'val/'+str(_['labels'])\n",
    "    if os.path.isdir(new_dir): #check if director exist the copy file\n",
    "        shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    else: #create folder with name label and copy over file \n",
    "        os.makedirs(new_dir)\n",
    "        shutil.copy(orig_dataset_dir+str(_['file_name']), new_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.18.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35420ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fef60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51a8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7162de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3547d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(orig_dataset_dir):\n",
    "    images = []\n",
    "    for i, filename in enumerate(os.listdir(orig_dataset_dir)):\n",
    "        #check label[i] value\n",
    "        label = str(labels[i])        \n",
    "        dst_dir = new_flower_dataset_dir+label\n",
    "        if os.path.isdir(dst_dir): #check if director exist the copy file\n",
    "            shutil.copy(orig_dataset_dir+filename, dst_dir)\n",
    "        else: #create folder with name label and copy over file \n",
    "            os.makedirs(dst_dir)\n",
    "            shutil.copy(orig_dataset_dir+filename, dst_dir)\n",
    "            \n",
    "        #if label value folder exists? if not create it else copy image[filename] to new directory\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5293a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_images_from_folder(orig_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c4711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8189 files belonging to 102 classes.\n",
      "Using 7371 files for training.\n",
      "Found 8189 files belonging to 102 classes.\n",
      "Using 818 files for validation.\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    new_flower_dataset_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # categorical, binary\n",
    "    # class_names=['0', '1', '2', '3', ...]\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),  # reshape if not in this size\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    new_flower_dataset_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",  # categorical, binary\n",
    "    # class_names=['0', '1', '2', '3', ...]\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),  # reshape if not in this size\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "883307c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def augment(x, y):\\n    image = tf.image.random_brightness(x, max_delta=0.05)\\n    return image, y\\n\\n\\nds_train = ds_train.map(augment)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def augment(x, y):\n",
    "    image = tf.image.random_brightness(x, max_delta=0.05)\n",
    "    return image, y\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(augment)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effbc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0201c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "    \n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "\n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29d9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "optim_1 = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#n_steps = ds_train.samples // BATCH_SIZE\n",
    "#n_val_steps = ds_validation.samples // BATCH_SIZE\n",
    "\n",
    "# First we'll train the model without Fine-tuning\n",
    "vgg_model = create_model(input_shape, NUM_CLASSES, optim_1, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4343e06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "231/231 - 18s - loss: 4.6118 - accuracy: 0.0301 - val_loss: 4.6008 - val_accuracy: 0.0367\n",
      "Epoch 2/100\n",
      "231/231 - 18s - loss: 4.5875 - accuracy: 0.0309 - val_loss: 4.5818 - val_accuracy: 0.0367\n",
      "Epoch 3/100\n",
      "231/231 - 17s - loss: 4.5681 - accuracy: 0.0309 - val_loss: 4.5670 - val_accuracy: 0.0367\n",
      "Epoch 4/100\n",
      "231/231 - 17s - loss: 4.5525 - accuracy: 0.0309 - val_loss: 4.5554 - val_accuracy: 0.0367\n",
      "Epoch 5/100\n",
      "231/231 - 17s - loss: 4.5401 - accuracy: 0.0309 - val_loss: 4.5465 - val_accuracy: 0.0367\n",
      "Epoch 6/100\n",
      "231/231 - 17s - loss: 4.5304 - accuracy: 0.0309 - val_loss: 4.5396 - val_accuracy: 0.0367\n",
      "Epoch 7/100\n",
      "231/231 - 17s - loss: 4.5227 - accuracy: 0.0309 - val_loss: 4.5345 - val_accuracy: 0.0367\n",
      "Epoch 8/100\n",
      "231/231 - 16s - loss: 4.5169 - accuracy: 0.0309 - val_loss: 4.5307 - val_accuracy: 0.0367\n",
      "Epoch 9/100\n",
      "231/231 - 17s - loss: 4.5124 - accuracy: 0.0309 - val_loss: 4.5279 - val_accuracy: 0.0367\n",
      "Epoch 10/100\n",
      "231/231 - 17s - loss: 4.5090 - accuracy: 0.0301 - val_loss: 4.5260 - val_accuracy: 0.0367\n",
      "Epoch 11/100\n",
      "231/231 - 18s - loss: 4.5064 - accuracy: 0.0288 - val_loss: 4.5247 - val_accuracy: 0.0367\n",
      "Epoch 12/100\n",
      "231/231 - 18s - loss: 4.5045 - accuracy: 0.0279 - val_loss: 4.5237 - val_accuracy: 0.0367\n",
      "Epoch 13/100\n",
      "231/231 - 17s - loss: 4.5030 - accuracy: 0.0281 - val_loss: 4.5232 - val_accuracy: 0.0367\n",
      "Epoch 14/100\n",
      "231/231 - 18s - loss: 4.5019 - accuracy: 0.0305 - val_loss: 4.5229 - val_accuracy: 0.0244\n",
      "Epoch 15/100\n",
      "231/231 - 17s - loss: 4.5010 - accuracy: 0.0313 - val_loss: 4.5226 - val_accuracy: 0.0244\n",
      "Epoch 16/100\n",
      "231/231 - 17s - loss: 4.5004 - accuracy: 0.0313 - val_loss: 4.5226 - val_accuracy: 0.0244\n",
      "Epoch 17/100\n",
      "231/231 - 17s - loss: 4.4999 - accuracy: 0.0313 - val_loss: 4.5227 - val_accuracy: 0.0244\n",
      "Epoch 18/100\n",
      "231/231 - 17s - loss: 4.4996 - accuracy: 0.0313 - val_loss: 4.5227 - val_accuracy: 0.0244\n",
      "Epoch 19/100\n",
      "231/231 - 18s - loss: 4.4993 - accuracy: 0.0313 - val_loss: 4.5227 - val_accuracy: 0.0244\n",
      "Epoch 20/100\n",
      "231/231 - 18s - loss: 4.4991 - accuracy: 0.0313 - val_loss: 4.5229 - val_accuracy: 0.0244\n",
      "Epoch 21/100\n",
      "231/231 - 17s - loss: 4.4989 - accuracy: 0.0313 - val_loss: 4.5229 - val_accuracy: 0.0244\n",
      "Epoch 22/100\n",
      "231/231 - 17s - loss: 4.4988 - accuracy: 0.0313 - val_loss: 4.5231 - val_accuracy: 0.0244\n",
      "Epoch 23/100\n",
      "231/231 - 17s - loss: 4.4987 - accuracy: 0.0313 - val_loss: 4.5231 - val_accuracy: 0.0244\n",
      "Epoch 24/100\n",
      "231/231 - 18s - loss: 4.4986 - accuracy: 0.0313 - val_loss: 4.5231 - val_accuracy: 0.0244\n",
      "Epoch 25/100\n",
      "231/231 - 18s - loss: 4.4986 - accuracy: 0.0313 - val_loss: 4.5233 - val_accuracy: 0.0244\n",
      "Epoch 26/100\n",
      "231/231 - 18s - loss: 4.4986 - accuracy: 0.0313 - val_loss: 4.5233 - val_accuracy: 0.0244\n",
      "Epoch 27/100\n",
      "231/231 - 17s - loss: 4.4985 - accuracy: 0.0313 - val_loss: 4.5234 - val_accuracy: 0.0244\n",
      "Epoch 28/100\n",
      "231/231 - 18s - loss: 4.4985 - accuracy: 0.0313 - val_loss: 4.5235 - val_accuracy: 0.0244\n",
      "Epoch 29/100\n",
      "231/231 - 17s - loss: 4.4985 - accuracy: 0.0313 - val_loss: 4.5235 - val_accuracy: 0.0244\n",
      "Epoch 30/100\n",
      "231/231 - 18s - loss: 4.4985 - accuracy: 0.0313 - val_loss: 4.5236 - val_accuracy: 0.0244\n",
      "Epoch 31/100\n",
      "231/231 - 18s - loss: 4.4985 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 32/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5236 - val_accuracy: 0.0244\n",
      "Epoch 33/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5236 - val_accuracy: 0.0244\n",
      "Epoch 34/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 35/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 36/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 37/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 38/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 39/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5237 - val_accuracy: 0.0244\n",
      "Epoch 40/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5238 - val_accuracy: 0.0244\n",
      "Epoch 41/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5238 - val_accuracy: 0.0244\n",
      "Epoch 42/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5239 - val_accuracy: 0.0244\n",
      "Epoch 43/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5239 - val_accuracy: 0.0244\n",
      "Epoch 44/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 45/100\n",
      "231/231 - 19s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 46/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5239 - val_accuracy: 0.0244\n",
      "Epoch 47/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 48/100\n",
      "231/231 - 25s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5239 - val_accuracy: 0.0244\n",
      "Epoch 49/100\n",
      "231/231 - 30s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 50/100\n",
      "231/231 - 30s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 51/100\n",
      "231/231 - 32s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 52/100\n",
      "231/231 - 24s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 53/100\n",
      "231/231 - 25s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 54/100\n",
      "231/231 - 25s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 55/100\n",
      "231/231 - 19s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5240 - val_accuracy: 0.0244\n",
      "Epoch 56/100\n",
      "231/231 - 23s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 57/100\n",
      "231/231 - 26s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 58/100\n",
      "231/231 - 27s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 59/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 60/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 61/100\n",
      "231/231 - 19s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 62/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 63/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 64/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 65/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 66/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 67/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 68/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 69/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 70/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 71/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 72/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 73/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5241 - val_accuracy: 0.0244\n",
      "Epoch 74/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 75/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 76/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 77/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 78/100\n",
      "231/231 - 21s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 79/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 80/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 82/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 83/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 84/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 85/100\n",
      "231/231 - 17s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 86/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5243 - val_accuracy: 0.0244\n",
      "Epoch 87/100\n",
      "231/231 - 18s - loss: 4.4984 - accuracy: 0.0313 - val_loss: 4.5242 - val_accuracy: 0.0244\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-56f33e2aad17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m vgg_history = vgg_model.fit(ds_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             verbose=2)\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1123\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg_history = vgg_model.fit(ds_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=ds_validation,\n",
    "                            verbose=2,\n",
    "                            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5c65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307261b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c803e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b41ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0573a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5281150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172ab48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8beea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158e187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
