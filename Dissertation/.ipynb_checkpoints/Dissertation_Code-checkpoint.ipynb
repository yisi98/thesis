{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737f5f14",
   "metadata": {},
   "source": [
    "# Dissertation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3073d9",
   "metadata": {},
   "source": [
    "## Research into the techniques and methods to achieve state of the art accuracy in flower species identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c97bbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6984ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###imports###\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from scipy import io\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import logging\n",
    "#import skimage.io\n",
    "import random\n",
    "import PIL\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa11d15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a43f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbda12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///E:/Github/thesis/Dissertation/mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed53ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecf1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes all outputs be in float format rather than exponentials\n",
    "#np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c860a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "IMG_SIZE = 224 #this parameter sets image dimensions as 50*50\n",
    "DATE = datetime.datetime.now().strftime('%d-%b-%Y')\n",
    "MODEL_PATH = f'models/{DATE}/'\n",
    "MODEL_NAME = 'FlowerClassifierTrial.model'.format(int(time.time()))\n",
    "log_dir=f'logs\\\\{MODEL_NAME}'\n",
    "TENSORBOARD = TensorBoard(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c687c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ed7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbdd12",
   "metadata": {},
   "source": [
    "# Load Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1c4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###Directory for MacBook\n",
    "# mac_URL = '/Volumes/T7/Uni/Github/thesis/flowerDataset/Flower'\n",
    "# mac_labels = '/Volumes/T7/Uni/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "# mac_dataSplit = '/Volumes/T7/Uni/Github/thesis/flowerDataset/setid.mat'\n",
    "# mac_loaded_images = '/Volumes/T7/Uni/loaded_images.npy'\n",
    "# mac_image_train='/Volumes/T7/Uni/image_train.npy'\n",
    "# mac_label_train = '/Volumes/T7/Uni/label_train.npy'\n",
    "# mac_image_test = '/Volumes/T7/Uni/image_test.npy'\n",
    "# mac_label_test = '/Volumes/T7/Uni/label_test.npy'\n",
    "# mac_image_val = '/Volumes/T7/Uni/image_val.npy'\n",
    "# mac_label_val = '/Volumes/T7/Uni/label_val.npy'\n",
    "\n",
    "# ###Directory for PC\n",
    "# pc_URL = 'E:/Github/thesis/flowerDataset/Flower'\n",
    "# pc_labels = 'E:/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "# pc_dataSplit = 'E:/Github/thesis/flowerDataset/setid.mat'\n",
    "# pc_loaded_images = 'E:/Dissertation/data/loaded_images.npy'\n",
    "# pc_image_train = 'E:/Dissertation/data/image_train.npy'\n",
    "# pc_label_train = 'E:/Dissertation/data/label_train.npy'\n",
    "# pc_image_test = 'E:/Dissertation/data/image_test.npy'\n",
    "# pc_label_test = 'E:/Dissertation/data/label_test.npy'\n",
    "# pc_image_val = 'E:/Dissertation/data/image_val.npy'\n",
    "# pc_label_val = 'E:/Dissertation/data/label_val.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1180309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories():\n",
    "    if os.path.exists(mac_URL) and os.path.exists(mac_labels) and os.path.exists(\n",
    "            mac_dataSplit) and os.path.exists(mac_loaded_images):\n",
    "        return mac_URL, mac_labels, mac_dataSplit, mac_loaded_images, mac_image_train, mac_label_train, mac_image_test, mac_label_test,mac_image_val, mac_label_val \n",
    "    else:\n",
    "        return pc_URL, pc_labels, pc_dataSplit, pc_loaded_images, pc_image_train, pc_label_train, pc_image_test, pc_label_test, pc_image_val, pc_label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ec1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL_dir, labels_dir, dataSplit_dir, loaded_images_dir, image_train_dir, label_train_dir, image_test_dir, label_test_dir, image_val_dir, label_val_dir = get_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af5a630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_dir = 'E:/Github/thesis/flowerDataset/Flower'\n",
    "labels_dir = 'E:/Github/thesis/flowerDataset/imagelabels.mat'\n",
    "dataSplit_dir = 'E:/Github/thesis/flowerDataset/setid.mat'\n",
    "loaded_images_dir = 'E:/Dissertation/data/loaded_images.npy'\n",
    "image_train_dir ='E:/Dissertation/data/image_train.npy'\n",
    "label_train_dir = 'E:/Dissertation/data/label_train.npy'\n",
    "image_test_dir = 'E:/Dissertation/data/image_test.npy'\n",
    "label_test_dir = 'E:/Dissertation/data/label_test.npy'\n",
    "image_val_dir = 'E:/Dissertation/data/image_val.npy'\n",
    "label_val_dir = 'E:/Dissertation/data/label_val.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591cf84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Github/thesis/flowerDataset/imagelabels.mat\n"
     ]
    }
   ],
   "source": [
    "print(labels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f0c1a",
   "metadata": {},
   "source": [
    "### Load DataSet and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b53f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = io.loadmat(labels_dir)\n",
    "data_labels = data_labels.items()\n",
    "data_labels = list(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2554af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41c40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1][3][0] #loads the labels that is stored in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0b6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77, 77, 77, ..., 62, 62, 62], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed0a2854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b102eefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNIQUE_LABELS = np.unique(labels)\n",
    "UNIQUE_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ff41223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got loading files code from link below\n",
    "#https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder\n",
    "#Function gets all the images loaded up\n",
    "def load_images_from_folder(URL):\n",
    "    images = []\n",
    "    for filename in os.listdir(URL):\n",
    "        #img = cv2.imread(os.path.join(URL,filename))\n",
    "        img = cv2.resize(cv2.imread(os.path.join(URL,filename), cv2.COLOR_BGR2RGB), (IMG_SIZE, IMG_SIZE))\n",
    "        img = np.reshape(img,[IMG_SIZE,IMG_SIZE,3])\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    np.save(loaded_images_dir, images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563d6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to run this cell if image already loaded.\n",
    "#load_images_from_folder(URL_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b32b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if images are already loaded, just load the file here rather than running function again.\n",
    "image_data = np.load(loaded_images_dir, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0969fb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8189, 224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shows the shape of the image_data, the number of images, the dimensions and number of colour channels\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5eec5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4356b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine image with labels\n",
    "def randomised_dataset(image_data, labels):\n",
    "    np.random.seed(8)\n",
    "    indices = np.arange(image_data.shape[0])\n",
    "    print(indices)\n",
    "    np.random.shuffle(indices)\n",
    "    image_data = image_data[indices]\n",
    "    labels = labels[indices]\n",
    "    return image_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "965b929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_data, labels = randomised_dataset(image_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cebed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8189, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4efd03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Label Encoder\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "converted_labels = np.array(mlb.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09ba97fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b6fb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(labels):\n",
    "    new_labels = []\n",
    "    for i in range(len(labels)):\n",
    "        new_labels.insert(i, [labels[i]])\n",
    "    return np.array(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7430f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted_labels = convert_label(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e40f31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f70b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8189"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf733688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6dc2e",
   "metadata": {},
   "source": [
    "# Training and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64e30768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation code from https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
    "#splitting the image dataset into the ratio for training, validation and testing data\n",
    "def split_data(image_data, converted_labels):\n",
    "    \n",
    "    train_ratio = 0.75\n",
    "    validation_ratio = 0.15\n",
    "    test_ratio = 0.10\n",
    "\n",
    "    image_train, image_test, label_train, label_test = train_test_split(image_data, converted_labels, test_size=1 - train_ratio, random_state=42)\n",
    "\n",
    "    #the test from previous line which is 25% of dataset is passed into the line below to be \n",
    "    #further split into 15% for validation and 10% for testing\n",
    "\n",
    "    image_val, image_test, label_val, label_test = train_test_split(image_test, label_test, test_size=test_ratio/(test_ratio + validation_ratio),random_state=42) \n",
    "\n",
    "    print('image_train',image_train.shape)\n",
    "    print('label_train',label_train.shape)\n",
    "    print('image_test',image_test.shape)\n",
    "    print('label_test',label_test.shape)\n",
    "    print('image_val', image_val.shape)\n",
    "    print('label_val', label_val.shape)\n",
    "\n",
    "    np.save(image_train_dir, image_train)\n",
    "    np.save(label_train_dir, label_train)\n",
    "    np.save(image_test_dir, image_test)\n",
    "    np.save(label_test_dir, label_test)\n",
    "    np.save(image_val_dir, image_val)\n",
    "    np.save(label_val_dir, label_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d985813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_train (6141, 224, 224, 3)\n",
      "label_train (6141, 102)\n",
      "image_test (820, 224, 224, 3)\n",
      "label_test (820, 102)\n",
      "image_val (1228, 224, 224, 3)\n",
      "label_val (1228, 102)\n"
     ]
    }
   ],
   "source": [
    "split_data(image_data,converted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aee55642",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = np.load(image_train_dir, allow_pickle=True)\n",
    "image_test = np.load(image_test_dir, allow_pickle=True)\n",
    "label_train = np.load(label_train_dir, allow_pickle=True)\n",
    "label_test = np.load(label_test_dir, allow_pickle=True)\n",
    "image_val = np.load(image_val_dir, allow_pickle=True)\n",
    "label_val = np.load(label_val_dir, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "606a621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 224, 224, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "952d08fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_val[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a1187",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff6920dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the images to the range of 0 - 1.0 \n",
    "image_train = image_train/255.0\n",
    "image_test = image_test/255.0\n",
    "image_val = image_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1bb389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 224, 224, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e534027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 102)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "312de917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 102)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90564584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8328cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55d0ae0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of classes/ flowers\n",
    "NUM_CLASSES = 102\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "040ac502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6141, 102)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1925a731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18204d6a",
   "metadata": {},
   "source": [
    "# Custom CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc375b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of model\n",
    "name_model = 'test-{}'.format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81c56ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 300\n",
    "verbose= 2\n",
    "act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6597d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(act):\n",
    "    # tf.reset_default_graph()\n",
    "    model = Sequential()\n",
    "    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "    \n",
    "    # INPUT LAYER\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation(act))\n",
    "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # HIDDEN LAYER 1\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # HIDDEN LAYER 2\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # HIDDEN LAYER 3\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # HIDDEN LAYER 4\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation(act))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # Fully Connected\n",
    "    model.add(Flatten()) # converts the 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation(act))\n",
    "    model.add(Dropout(0.25)) # reduces overfitting\n",
    "\n",
    "    # OUTPUT LAYER\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6803cb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_cnn_model(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53d5fff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 220, 220, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 108, 108, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 54, 54, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 102)               26214     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 102)               0         \n",
      "=================================================================\n",
      "Total params: 9,863,238\n",
      "Trainable params: 9,862,278\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2c8b375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#history = model.fit(image_train, label_train, batch_size=64, epochs=100, validation_data=(image_val, label_val), verbose=1, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7e4887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "#model.save(f'{MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff2059af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model\n",
    "#model =  tf.keras.models.load_model(f'{MODEL_PATH}')\n",
    "#model = tf.keras.models.load_model(f'E:/GoogleSync/Masters/Dissertation/models/24-Jun-2021') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170a1d3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27a9ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c30171a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/08/06 20:20:49 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of keras. If you encounter errors during autologging, try upgrading / downgrading keras to a supported version, or try upgrading MLflow.\n",
      "2021/08/06 20:20:49 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0330s vs `on_train_batch_end` time: 0.0720s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0330s vs `on_train_batch_end` time: 0.0720s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 - 17s - loss: 5.7470 - accuracy: 0.0295 - val_loss: 6.0310 - val_accuracy: 0.0138\n",
      "Epoch 2/300\n",
      "192/192 - 7s - loss: 4.8539 - accuracy: 0.0337 - val_loss: 4.6617 - val_accuracy: 0.0301\n",
      "Epoch 3/300\n",
      "192/192 - 7s - loss: 4.5581 - accuracy: 0.0518 - val_loss: 4.9574 - val_accuracy: 0.0440\n",
      "Epoch 4/300\n",
      "192/192 - 7s - loss: 4.4737 - accuracy: 0.0607 - val_loss: 5.1288 - val_accuracy: 0.0562\n",
      "Epoch 5/300\n",
      "192/192 - 7s - loss: 4.3752 - accuracy: 0.0716 - val_loss: 4.7948 - val_accuracy: 0.0554\n",
      "Epoch 6/300\n",
      "192/192 - 7s - loss: 4.3571 - accuracy: 0.0791 - val_loss: 5.2395 - val_accuracy: 0.0489\n",
      "Epoch 7/300\n",
      "192/192 - 7s - loss: 4.2629 - accuracy: 0.0914 - val_loss: 5.0772 - val_accuracy: 0.0708\n",
      "Epoch 8/300\n",
      "192/192 - 7s - loss: 4.1752 - accuracy: 0.0987 - val_loss: 5.6486 - val_accuracy: 0.0603\n",
      "Epoch 9/300\n",
      "192/192 - 7s - loss: 4.1124 - accuracy: 0.1052 - val_loss: 5.1370 - val_accuracy: 0.0765\n",
      "Epoch 10/300\n",
      "192/192 - 7s - loss: 4.0030 - accuracy: 0.1205 - val_loss: 4.8207 - val_accuracy: 0.0855\n",
      "Epoch 11/300\n",
      "192/192 - 7s - loss: 3.9265 - accuracy: 0.1298 - val_loss: 4.5349 - val_accuracy: 0.0774\n",
      "Epoch 12/300\n",
      "192/192 - 7s - loss: 3.8615 - accuracy: 0.1379 - val_loss: 4.4378 - val_accuracy: 0.0888\n",
      "Epoch 13/300\n",
      "192/192 - 7s - loss: 3.7637 - accuracy: 0.1493 - val_loss: 4.8099 - val_accuracy: 0.0814\n",
      "Epoch 14/300\n",
      "192/192 - 7s - loss: 3.6876 - accuracy: 0.1676 - val_loss: 4.3875 - val_accuracy: 0.1148\n",
      "Epoch 15/300\n",
      "192/192 - 7s - loss: 3.6031 - accuracy: 0.1791 - val_loss: 6.0053 - val_accuracy: 0.0855\n",
      "Epoch 16/300\n",
      "192/192 - 7s - loss: 3.4689 - accuracy: 0.1938 - val_loss: 4.2500 - val_accuracy: 0.1132\n",
      "Epoch 17/300\n",
      "192/192 - 7s - loss: 3.3251 - accuracy: 0.2115 - val_loss: 4.3729 - val_accuracy: 0.1221\n",
      "Epoch 18/300\n",
      "192/192 - 7s - loss: 3.2121 - accuracy: 0.2255 - val_loss: 4.0538 - val_accuracy: 0.1458\n",
      "Epoch 19/300\n",
      "192/192 - 7s - loss: 3.0632 - accuracy: 0.2457 - val_loss: 3.9180 - val_accuracy: 0.1450\n",
      "Epoch 20/300\n",
      "192/192 - 7s - loss: 2.8916 - accuracy: 0.2742 - val_loss: 3.7584 - val_accuracy: 0.1539\n",
      "Epoch 21/300\n",
      "192/192 - 7s - loss: 2.7716 - accuracy: 0.2943 - val_loss: 3.9042 - val_accuracy: 0.1946\n",
      "Epoch 22/300\n",
      "192/192 - 7s - loss: 2.6140 - accuracy: 0.3200 - val_loss: 3.7392 - val_accuracy: 0.1987\n",
      "Epoch 23/300\n",
      "192/192 - 7s - loss: 2.4947 - accuracy: 0.3390 - val_loss: 3.4339 - val_accuracy: 0.2150\n",
      "Epoch 24/300\n",
      "192/192 - 7s - loss: 2.3288 - accuracy: 0.3589 - val_loss: 3.3322 - val_accuracy: 0.2378\n",
      "Epoch 25/300\n",
      "192/192 - 7s - loss: 2.2232 - accuracy: 0.3946 - val_loss: 3.3512 - val_accuracy: 0.2353\n",
      "Epoch 26/300\n",
      "192/192 - 7s - loss: 2.0959 - accuracy: 0.4235 - val_loss: 3.3879 - val_accuracy: 0.2752\n",
      "Epoch 27/300\n",
      "192/192 - 7s - loss: 1.9868 - accuracy: 0.4519 - val_loss: 3.5339 - val_accuracy: 0.2288\n",
      "Epoch 28/300\n",
      "192/192 - 7s - loss: 1.8627 - accuracy: 0.4761 - val_loss: 3.2953 - val_accuracy: 0.2842\n",
      "Epoch 29/300\n",
      "192/192 - 7s - loss: 1.7992 - accuracy: 0.4905 - val_loss: 3.5573 - val_accuracy: 0.3078\n",
      "Epoch 30/300\n",
      "192/192 - 7s - loss: 1.6177 - accuracy: 0.5260 - val_loss: 3.3100 - val_accuracy: 0.2704\n",
      "Epoch 31/300\n",
      "192/192 - 7s - loss: 1.4999 - accuracy: 0.5651 - val_loss: 3.6496 - val_accuracy: 0.3225\n",
      "Epoch 32/300\n",
      "192/192 - 7s - loss: 1.4290 - accuracy: 0.5817 - val_loss: 3.2259 - val_accuracy: 0.2801\n",
      "Epoch 33/300\n",
      "192/192 - 7s - loss: 1.3074 - accuracy: 0.6196 - val_loss: 3.5120 - val_accuracy: 0.3111\n",
      "Epoch 34/300\n",
      "192/192 - 7s - loss: 1.2544 - accuracy: 0.6354 - val_loss: 3.6500 - val_accuracy: 0.3257\n",
      "Epoch 35/300\n",
      "192/192 - 7s - loss: 1.2081 - accuracy: 0.6455 - val_loss: 3.3507 - val_accuracy: 0.3347\n",
      "Epoch 36/300\n",
      "192/192 - 7s - loss: 1.0378 - accuracy: 0.6921 - val_loss: 3.2635 - val_accuracy: 0.3436\n",
      "Epoch 37/300\n",
      "192/192 - 7s - loss: 1.0412 - accuracy: 0.6890 - val_loss: 3.7879 - val_accuracy: 0.3567\n",
      "Epoch 38/300\n",
      "192/192 - 7s - loss: 0.9581 - accuracy: 0.7119 - val_loss: 4.4203 - val_accuracy: 0.3844\n",
      "Epoch 39/300\n",
      "192/192 - 7s - loss: 0.9050 - accuracy: 0.7318 - val_loss: 3.1522 - val_accuracy: 0.3086\n",
      "Epoch 40/300\n",
      "192/192 - 7s - loss: 0.8146 - accuracy: 0.7500 - val_loss: 3.3563 - val_accuracy: 0.3583\n",
      "Epoch 41/300\n",
      "192/192 - 7s - loss: 0.7683 - accuracy: 0.7660 - val_loss: 3.5956 - val_accuracy: 0.3982\n",
      "Epoch 42/300\n",
      "192/192 - 7s - loss: 0.7677 - accuracy: 0.7740 - val_loss: 3.9424 - val_accuracy: 0.3428\n",
      "Epoch 43/300\n",
      "192/192 - 7s - loss: 0.6841 - accuracy: 0.7929 - val_loss: 3.6200 - val_accuracy: 0.3966\n",
      "Epoch 44/300\n",
      "192/192 - 7s - loss: 0.6342 - accuracy: 0.8092 - val_loss: 3.7254 - val_accuracy: 0.3689\n",
      "Epoch 45/300\n",
      "192/192 - 7s - loss: 0.6169 - accuracy: 0.8113 - val_loss: 3.7119 - val_accuracy: 0.3974\n",
      "Epoch 46/300\n",
      "192/192 - 7s - loss: 0.5703 - accuracy: 0.8277 - val_loss: 3.5388 - val_accuracy: 0.3738\n",
      "Epoch 47/300\n",
      "192/192 - 7s - loss: 0.5146 - accuracy: 0.8394 - val_loss: 3.3827 - val_accuracy: 0.3640\n",
      "Epoch 48/300\n",
      "192/192 - 7s - loss: 0.4765 - accuracy: 0.8549 - val_loss: 3.4301 - val_accuracy: 0.4121\n",
      "Epoch 49/300\n",
      "192/192 - 7s - loss: 0.4627 - accuracy: 0.8551 - val_loss: 4.6415 - val_accuracy: 0.3526\n",
      "Epoch 50/300\n",
      "192/192 - 7s - loss: 0.4610 - accuracy: 0.8552 - val_loss: 3.2950 - val_accuracy: 0.3567\n",
      "Epoch 51/300\n",
      "192/192 - 7s - loss: 0.4233 - accuracy: 0.8634 - val_loss: 4.3871 - val_accuracy: 0.3868\n",
      "Epoch 52/300\n",
      "192/192 - 7s - loss: 0.4022 - accuracy: 0.8767 - val_loss: 3.4139 - val_accuracy: 0.3779\n",
      "Epoch 53/300\n",
      "192/192 - 7s - loss: 0.3820 - accuracy: 0.8841 - val_loss: 3.9246 - val_accuracy: 0.3184\n",
      "Epoch 54/300\n",
      "192/192 - 7s - loss: 0.3581 - accuracy: 0.8945 - val_loss: 4.2754 - val_accuracy: 0.3941\n",
      "Epoch 55/300\n",
      "192/192 - 7s - loss: 0.3647 - accuracy: 0.8891 - val_loss: 3.8291 - val_accuracy: 0.4104\n",
      "Epoch 56/300\n",
      "192/192 - 7s - loss: 0.3341 - accuracy: 0.8989 - val_loss: 5.1173 - val_accuracy: 0.4023\n",
      "Epoch 57/300\n",
      "192/192 - 7s - loss: 0.3010 - accuracy: 0.9073 - val_loss: 3.9478 - val_accuracy: 0.3925\n",
      "Epoch 58/300\n",
      "192/192 - 7s - loss: 0.3095 - accuracy: 0.9069 - val_loss: 3.7516 - val_accuracy: 0.4072\n",
      "Epoch 59/300\n",
      "192/192 - 7s - loss: 0.2880 - accuracy: 0.9103 - val_loss: 4.4937 - val_accuracy: 0.3917\n",
      "Epoch 60/300\n",
      "192/192 - 7s - loss: 0.2864 - accuracy: 0.9109 - val_loss: 4.7485 - val_accuracy: 0.3347\n",
      "Epoch 61/300\n",
      "192/192 - 7s - loss: 0.2728 - accuracy: 0.9137 - val_loss: 4.9863 - val_accuracy: 0.3884\n",
      "Epoch 62/300\n",
      "192/192 - 7s - loss: 0.2653 - accuracy: 0.9200 - val_loss: 6.8182 - val_accuracy: 0.3836\n",
      "Epoch 63/300\n",
      "192/192 - 7s - loss: 0.2559 - accuracy: 0.9209 - val_loss: 4.0327 - val_accuracy: 0.3933\n",
      "Epoch 64/300\n",
      "192/192 - 7s - loss: 0.2585 - accuracy: 0.9230 - val_loss: 5.7646 - val_accuracy: 0.4031\n",
      "Epoch 65/300\n",
      "192/192 - 7s - loss: 0.2520 - accuracy: 0.9220 - val_loss: 4.3065 - val_accuracy: 0.3925\n",
      "Epoch 66/300\n",
      "192/192 - 7s - loss: 0.2221 - accuracy: 0.9297 - val_loss: 4.6699 - val_accuracy: 0.4169\n",
      "Epoch 67/300\n",
      "192/192 - 7s - loss: 0.2133 - accuracy: 0.9355 - val_loss: 4.5995 - val_accuracy: 0.4096\n",
      "Epoch 68/300\n",
      "192/192 - 7s - loss: 0.2025 - accuracy: 0.9388 - val_loss: 3.7165 - val_accuracy: 0.3917\n",
      "Epoch 69/300\n",
      "192/192 - 7s - loss: 0.2266 - accuracy: 0.9311 - val_loss: 5.1189 - val_accuracy: 0.4007\n",
      "Epoch 70/300\n",
      "192/192 - 7s - loss: 0.1824 - accuracy: 0.9453 - val_loss: 3.9591 - val_accuracy: 0.4129\n",
      "Epoch 71/300\n",
      "192/192 - 7s - loss: 0.1864 - accuracy: 0.9450 - val_loss: 4.5021 - val_accuracy: 0.4332\n",
      "Epoch 72/300\n",
      "192/192 - 7s - loss: 0.1788 - accuracy: 0.9464 - val_loss: 3.7670 - val_accuracy: 0.4145\n",
      "Epoch 73/300\n",
      "192/192 - 7s - loss: 0.1706 - accuracy: 0.9511 - val_loss: 4.4856 - val_accuracy: 0.4055\n",
      "Epoch 74/300\n",
      "192/192 - 7s - loss: 0.1742 - accuracy: 0.9476 - val_loss: 4.2960 - val_accuracy: 0.3982\n",
      "Epoch 75/300\n",
      "192/192 - 7s - loss: 0.1598 - accuracy: 0.9502 - val_loss: 4.5380 - val_accuracy: 0.4275\n",
      "Epoch 76/300\n",
      "192/192 - 7s - loss: 0.1523 - accuracy: 0.9518 - val_loss: 6.3184 - val_accuracy: 0.3656\n",
      "Epoch 77/300\n",
      "192/192 - 7s - loss: 0.1613 - accuracy: 0.9487 - val_loss: 4.8190 - val_accuracy: 0.4039\n",
      "Epoch 78/300\n",
      "192/192 - 7s - loss: 0.1504 - accuracy: 0.9516 - val_loss: 6.3490 - val_accuracy: 0.3135\n",
      "Epoch 79/300\n",
      "192/192 - 7s - loss: 0.1426 - accuracy: 0.9544 - val_loss: 4.0773 - val_accuracy: 0.4169\n",
      "Epoch 80/300\n",
      "192/192 - 7s - loss: 0.1400 - accuracy: 0.9557 - val_loss: 4.7700 - val_accuracy: 0.3860\n",
      "Epoch 81/300\n",
      "192/192 - 7s - loss: 0.1396 - accuracy: 0.9583 - val_loss: 5.2686 - val_accuracy: 0.3844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "192/192 - 7s - loss: 0.1364 - accuracy: 0.9557 - val_loss: 4.8968 - val_accuracy: 0.4365\n",
      "Epoch 83/300\n",
      "192/192 - 7s - loss: 0.1364 - accuracy: 0.9575 - val_loss: 3.9558 - val_accuracy: 0.3591\n",
      "Epoch 84/300\n",
      "192/192 - 7s - loss: 0.1325 - accuracy: 0.9603 - val_loss: 4.9667 - val_accuracy: 0.4169\n",
      "Epoch 85/300\n",
      "192/192 - 7s - loss: 0.1250 - accuracy: 0.9603 - val_loss: 4.6873 - val_accuracy: 0.4137\n",
      "Epoch 86/300\n",
      "192/192 - 7s - loss: 0.1267 - accuracy: 0.9611 - val_loss: 4.5634 - val_accuracy: 0.4137\n",
      "Epoch 87/300\n",
      "192/192 - 7s - loss: 0.1232 - accuracy: 0.9603 - val_loss: 5.6044 - val_accuracy: 0.4226\n",
      "Epoch 88/300\n",
      "192/192 - 7s - loss: 0.1089 - accuracy: 0.9669 - val_loss: 4.8328 - val_accuracy: 0.4308\n",
      "Epoch 89/300\n",
      "192/192 - 7s - loss: 0.1103 - accuracy: 0.9665 - val_loss: 5.0447 - val_accuracy: 0.4145\n",
      "Epoch 90/300\n",
      "192/192 - 7s - loss: 0.1103 - accuracy: 0.9656 - val_loss: 4.1778 - val_accuracy: 0.4235\n",
      "Epoch 91/300\n",
      "192/192 - 7s - loss: 0.1204 - accuracy: 0.9656 - val_loss: 7.5571 - val_accuracy: 0.4080\n",
      "Epoch 92/300\n",
      "192/192 - 7s - loss: 0.1306 - accuracy: 0.9638 - val_loss: 4.0625 - val_accuracy: 0.4104\n",
      "Epoch 93/300\n",
      "192/192 - 7s - loss: 0.1169 - accuracy: 0.9652 - val_loss: 5.0731 - val_accuracy: 0.4463\n",
      "Epoch 94/300\n",
      "192/192 - 7s - loss: 0.1274 - accuracy: 0.9621 - val_loss: 4.3541 - val_accuracy: 0.4023\n",
      "Epoch 95/300\n",
      "192/192 - 7s - loss: 0.0991 - accuracy: 0.9687 - val_loss: 5.3352 - val_accuracy: 0.4080\n",
      "Epoch 96/300\n",
      "192/192 - 7s - loss: 0.0946 - accuracy: 0.9726 - val_loss: 4.1293 - val_accuracy: 0.4055\n",
      "Epoch 97/300\n",
      "192/192 - 7s - loss: 0.1119 - accuracy: 0.9666 - val_loss: 4.3998 - val_accuracy: 0.3819\n",
      "Epoch 98/300\n",
      "192/192 - 7s - loss: 0.0905 - accuracy: 0.9717 - val_loss: 4.6347 - val_accuracy: 0.4178\n",
      "Epoch 99/300\n",
      "192/192 - 7s - loss: 0.0853 - accuracy: 0.9725 - val_loss: 5.1810 - val_accuracy: 0.4300\n",
      "Epoch 100/300\n",
      "192/192 - 7s - loss: 0.0748 - accuracy: 0.9746 - val_loss: 5.5308 - val_accuracy: 0.4031\n",
      "Epoch 101/300\n",
      "192/192 - 7s - loss: 0.1051 - accuracy: 0.9702 - val_loss: 4.3547 - val_accuracy: 0.3933\n",
      "Epoch 102/300\n",
      "192/192 - 7s - loss: 0.0949 - accuracy: 0.9718 - val_loss: 6.7949 - val_accuracy: 0.3542\n",
      "Epoch 103/300\n",
      "192/192 - 7s - loss: 0.0874 - accuracy: 0.9723 - val_loss: 5.3941 - val_accuracy: 0.4169\n",
      "Epoch 104/300\n",
      "192/192 - 7s - loss: 0.0990 - accuracy: 0.9700 - val_loss: 5.4136 - val_accuracy: 0.3787\n",
      "Epoch 105/300\n",
      "192/192 - 7s - loss: 0.0863 - accuracy: 0.9752 - val_loss: 5.9744 - val_accuracy: 0.4194\n",
      "Epoch 106/300\n",
      "192/192 - 7s - loss: 0.0809 - accuracy: 0.9767 - val_loss: 7.3518 - val_accuracy: 0.4129\n",
      "Epoch 107/300\n",
      "192/192 - 7s - loss: 0.0785 - accuracy: 0.9754 - val_loss: 5.6799 - val_accuracy: 0.3518\n",
      "Epoch 108/300\n",
      "192/192 - 7s - loss: 0.0910 - accuracy: 0.9713 - val_loss: 5.2938 - val_accuracy: 0.3966\n",
      "Epoch 109/300\n",
      "192/192 - 7s - loss: 0.0966 - accuracy: 0.9717 - val_loss: 5.3203 - val_accuracy: 0.3990\n",
      "Epoch 110/300\n",
      "192/192 - 7s - loss: 0.0721 - accuracy: 0.9780 - val_loss: 4.7678 - val_accuracy: 0.3966\n",
      "Epoch 111/300\n",
      "192/192 - 7s - loss: 0.0762 - accuracy: 0.9777 - val_loss: 4.7780 - val_accuracy: 0.4292\n",
      "Epoch 112/300\n",
      "192/192 - 7s - loss: 0.0823 - accuracy: 0.9741 - val_loss: 7.5241 - val_accuracy: 0.4259\n",
      "Epoch 113/300\n",
      "192/192 - 7s - loss: 0.0769 - accuracy: 0.9775 - val_loss: 4.7527 - val_accuracy: 0.3860\n",
      "Epoch 114/300\n",
      "192/192 - 7s - loss: 0.0755 - accuracy: 0.9788 - val_loss: 6.2368 - val_accuracy: 0.3998\n",
      "Epoch 115/300\n",
      "192/192 - 7s - loss: 0.0892 - accuracy: 0.9749 - val_loss: 7.4606 - val_accuracy: 0.3933\n",
      "Epoch 116/300\n",
      "192/192 - 7s - loss: 0.0735 - accuracy: 0.9785 - val_loss: 8.7453 - val_accuracy: 0.3298\n",
      "Epoch 117/300\n",
      "192/192 - 7s - loss: 0.0802 - accuracy: 0.9775 - val_loss: 4.5171 - val_accuracy: 0.3982\n",
      "Epoch 118/300\n",
      "192/192 - 7s - loss: 0.0832 - accuracy: 0.9748 - val_loss: 5.5898 - val_accuracy: 0.4112\n",
      "Epoch 119/300\n",
      "192/192 - 7s - loss: 0.0719 - accuracy: 0.9783 - val_loss: 4.8614 - val_accuracy: 0.2907\n",
      "Epoch 120/300\n",
      "192/192 - 7s - loss: 0.0672 - accuracy: 0.9798 - val_loss: 4.0478 - val_accuracy: 0.3656\n",
      "Epoch 121/300\n",
      "192/192 - 7s - loss: 0.0783 - accuracy: 0.9787 - val_loss: 5.6779 - val_accuracy: 0.4169\n",
      "Epoch 122/300\n",
      "192/192 - 7s - loss: 0.0831 - accuracy: 0.9764 - val_loss: 5.6704 - val_accuracy: 0.4560\n",
      "Epoch 123/300\n",
      "192/192 - 7s - loss: 0.0891 - accuracy: 0.9762 - val_loss: 5.7440 - val_accuracy: 0.4275\n",
      "Epoch 124/300\n",
      "192/192 - 7s - loss: 0.0778 - accuracy: 0.9788 - val_loss: 3.9906 - val_accuracy: 0.3852\n",
      "Epoch 125/300\n",
      "192/192 - 7s - loss: 0.0545 - accuracy: 0.9826 - val_loss: 5.7601 - val_accuracy: 0.4397\n",
      "Epoch 126/300\n",
      "192/192 - 7s - loss: 0.0560 - accuracy: 0.9827 - val_loss: 5.3627 - val_accuracy: 0.4316\n",
      "Epoch 127/300\n",
      "192/192 - 7s - loss: 0.0569 - accuracy: 0.9829 - val_loss: 7.2387 - val_accuracy: 0.4292\n",
      "Epoch 128/300\n",
      "192/192 - 7s - loss: 0.0523 - accuracy: 0.9853 - val_loss: 6.1258 - val_accuracy: 0.3770\n",
      "Epoch 129/300\n",
      "192/192 - 7s - loss: 0.0733 - accuracy: 0.9792 - val_loss: 4.9303 - val_accuracy: 0.4373\n",
      "Epoch 130/300\n",
      "192/192 - 7s - loss: 0.0626 - accuracy: 0.9814 - val_loss: 6.3057 - val_accuracy: 0.3966\n",
      "Epoch 131/300\n",
      "192/192 - 7s - loss: 0.0639 - accuracy: 0.9819 - val_loss: 5.4671 - val_accuracy: 0.3950\n",
      "Epoch 132/300\n",
      "192/192 - 7s - loss: 0.0699 - accuracy: 0.9816 - val_loss: 3.7299 - val_accuracy: 0.3697\n",
      "Epoch 133/300\n",
      "192/192 - 7s - loss: 0.0608 - accuracy: 0.9840 - val_loss: 5.0929 - val_accuracy: 0.4365\n",
      "Epoch 134/300\n",
      "192/192 - 7s - loss: 0.0464 - accuracy: 0.9853 - val_loss: 5.2387 - val_accuracy: 0.4275\n",
      "Epoch 135/300\n",
      "192/192 - 7s - loss: 0.0637 - accuracy: 0.9824 - val_loss: 5.9062 - val_accuracy: 0.3860\n",
      "Epoch 136/300\n",
      "192/192 - 7s - loss: 0.0707 - accuracy: 0.9783 - val_loss: 6.2830 - val_accuracy: 0.4308\n",
      "Epoch 137/300\n",
      "192/192 - 7s - loss: 0.0723 - accuracy: 0.9811 - val_loss: 5.6252 - val_accuracy: 0.4186\n",
      "Epoch 138/300\n",
      "192/192 - 7s - loss: 0.0731 - accuracy: 0.9798 - val_loss: 5.7390 - val_accuracy: 0.4373\n",
      "Epoch 139/300\n",
      "192/192 - 7s - loss: 0.0691 - accuracy: 0.9801 - val_loss: 4.8779 - val_accuracy: 0.4544\n",
      "Epoch 140/300\n",
      "192/192 - 7s - loss: 0.0569 - accuracy: 0.9826 - val_loss: 4.8957 - val_accuracy: 0.4292\n",
      "Epoch 141/300\n",
      "192/192 - 7s - loss: 0.0519 - accuracy: 0.9842 - val_loss: 6.1243 - val_accuracy: 0.4552\n",
      "Epoch 142/300\n",
      "192/192 - 7s - loss: 0.0544 - accuracy: 0.9840 - val_loss: 5.0018 - val_accuracy: 0.4349\n",
      "Epoch 143/300\n",
      "192/192 - 7s - loss: 0.0573 - accuracy: 0.9842 - val_loss: 6.3318 - val_accuracy: 0.4332\n",
      "Epoch 144/300\n",
      "192/192 - 7s - loss: 0.0547 - accuracy: 0.9829 - val_loss: 6.5767 - val_accuracy: 0.4300\n",
      "Epoch 145/300\n",
      "192/192 - 7s - loss: 0.0779 - accuracy: 0.9811 - val_loss: 7.2222 - val_accuracy: 0.4039\n",
      "Epoch 146/300\n",
      "192/192 - 7s - loss: 0.0630 - accuracy: 0.9816 - val_loss: 5.5968 - val_accuracy: 0.4104\n",
      "Epoch 147/300\n",
      "192/192 - 7s - loss: 0.0676 - accuracy: 0.9818 - val_loss: 6.1858 - val_accuracy: 0.4096\n",
      "Epoch 148/300\n",
      "192/192 - 7s - loss: 0.0610 - accuracy: 0.9844 - val_loss: 5.5297 - val_accuracy: 0.4218\n",
      "Epoch 149/300\n",
      "192/192 - 7s - loss: 0.0552 - accuracy: 0.9852 - val_loss: 5.3939 - val_accuracy: 0.4487\n",
      "Epoch 150/300\n",
      "192/192 - 7s - loss: 0.0467 - accuracy: 0.9857 - val_loss: 5.2805 - val_accuracy: 0.4324\n",
      "Epoch 151/300\n",
      "192/192 - 7s - loss: 0.0525 - accuracy: 0.9847 - val_loss: 4.9018 - val_accuracy: 0.4446\n",
      "Epoch 152/300\n",
      "192/192 - 7s - loss: 0.0581 - accuracy: 0.9824 - val_loss: 5.7977 - val_accuracy: 0.3966\n",
      "Epoch 153/300\n",
      "192/192 - 7s - loss: 0.0533 - accuracy: 0.9842 - val_loss: 4.6575 - val_accuracy: 0.4161\n",
      "Epoch 154/300\n",
      "192/192 - 7s - loss: 0.0477 - accuracy: 0.9858 - val_loss: 4.7702 - val_accuracy: 0.4047\n",
      "Epoch 155/300\n",
      "192/192 - 7s - loss: 0.0530 - accuracy: 0.9862 - val_loss: 5.4367 - val_accuracy: 0.4397\n",
      "Epoch 156/300\n",
      "192/192 - 7s - loss: 0.0462 - accuracy: 0.9860 - val_loss: 5.3938 - val_accuracy: 0.4259\n",
      "Epoch 157/300\n",
      "192/192 - 7s - loss: 0.0477 - accuracy: 0.9862 - val_loss: 5.7995 - val_accuracy: 0.3990\n",
      "Epoch 158/300\n",
      "192/192 - 7s - loss: 0.0577 - accuracy: 0.9842 - val_loss: 5.4223 - val_accuracy: 0.4129\n",
      "Epoch 159/300\n",
      "192/192 - 7s - loss: 0.0387 - accuracy: 0.9876 - val_loss: 5.1257 - val_accuracy: 0.4251\n",
      "Epoch 160/300\n",
      "192/192 - 7s - loss: 0.0504 - accuracy: 0.9853 - val_loss: 7.5914 - val_accuracy: 0.4243\n",
      "Epoch 161/300\n",
      "192/192 - 7s - loss: 0.0335 - accuracy: 0.9906 - val_loss: 6.8330 - val_accuracy: 0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/300\n",
      "192/192 - 7s - loss: 0.0555 - accuracy: 0.9855 - val_loss: 5.0634 - val_accuracy: 0.4145\n",
      "Epoch 163/300\n",
      "192/192 - 7s - loss: 0.0495 - accuracy: 0.9847 - val_loss: 6.4881 - val_accuracy: 0.4316\n",
      "Epoch 164/300\n",
      "192/192 - 7s - loss: 0.0452 - accuracy: 0.9879 - val_loss: 10.0562 - val_accuracy: 0.3314\n",
      "Epoch 165/300\n",
      "192/192 - 7s - loss: 0.0549 - accuracy: 0.9862 - val_loss: 7.0375 - val_accuracy: 0.3950\n",
      "Epoch 166/300\n",
      "192/192 - 7s - loss: 0.0485 - accuracy: 0.9865 - val_loss: 5.5464 - val_accuracy: 0.4283\n",
      "Epoch 167/300\n",
      "192/192 - 7s - loss: 0.0390 - accuracy: 0.9865 - val_loss: 5.5355 - val_accuracy: 0.4292\n",
      "Epoch 168/300\n",
      "192/192 - 7s - loss: 0.0517 - accuracy: 0.9845 - val_loss: 5.6105 - val_accuracy: 0.3852\n",
      "Epoch 169/300\n",
      "192/192 - 7s - loss: 0.0404 - accuracy: 0.9878 - val_loss: 6.3136 - val_accuracy: 0.4430\n",
      "Epoch 170/300\n",
      "192/192 - 7s - loss: 0.0437 - accuracy: 0.9862 - val_loss: 8.1259 - val_accuracy: 0.4324\n",
      "Epoch 171/300\n",
      "192/192 - 7s - loss: 0.0350 - accuracy: 0.9897 - val_loss: 6.8120 - val_accuracy: 0.4577\n",
      "Epoch 172/300\n",
      "192/192 - 7s - loss: 0.0426 - accuracy: 0.9866 - val_loss: 6.5853 - val_accuracy: 0.4218\n",
      "Epoch 173/300\n",
      "192/192 - 7s - loss: 0.0334 - accuracy: 0.9896 - val_loss: 8.2523 - val_accuracy: 0.3844\n",
      "Epoch 174/300\n",
      "192/192 - 7s - loss: 0.0310 - accuracy: 0.9901 - val_loss: 6.0651 - val_accuracy: 0.3974\n",
      "Epoch 175/300\n",
      "192/192 - 7s - loss: 0.0458 - accuracy: 0.9866 - val_loss: 7.2899 - val_accuracy: 0.4064\n",
      "Epoch 176/300\n",
      "192/192 - 7s - loss: 0.0500 - accuracy: 0.9863 - val_loss: 5.4816 - val_accuracy: 0.3599\n",
      "Epoch 177/300\n",
      "192/192 - 7s - loss: 0.0687 - accuracy: 0.9831 - val_loss: 8.3644 - val_accuracy: 0.4283\n",
      "Epoch 178/300\n",
      "192/192 - 7s - loss: 0.0475 - accuracy: 0.9879 - val_loss: 7.5764 - val_accuracy: 0.4275\n",
      "Epoch 179/300\n",
      "192/192 - 7s - loss: 0.0346 - accuracy: 0.9899 - val_loss: 5.9111 - val_accuracy: 0.4064\n",
      "Epoch 180/300\n",
      "192/192 - 7s - loss: 0.0310 - accuracy: 0.9915 - val_loss: 5.9531 - val_accuracy: 0.4552\n",
      "Epoch 181/300\n",
      "192/192 - 7s - loss: 0.0529 - accuracy: 0.9865 - val_loss: 6.1999 - val_accuracy: 0.3860\n",
      "Epoch 182/300\n",
      "192/192 - 7s - loss: 0.0420 - accuracy: 0.9888 - val_loss: 8.7507 - val_accuracy: 0.4088\n",
      "Epoch 183/300\n",
      "192/192 - 7s - loss: 0.0464 - accuracy: 0.9883 - val_loss: 6.0339 - val_accuracy: 0.4194\n",
      "Epoch 184/300\n",
      "192/192 - 7s - loss: 0.0436 - accuracy: 0.9881 - val_loss: 6.4539 - val_accuracy: 0.4349\n",
      "Epoch 185/300\n",
      "192/192 - 7s - loss: 0.0358 - accuracy: 0.9902 - val_loss: 6.7935 - val_accuracy: 0.4243\n",
      "Epoch 186/300\n",
      "192/192 - 7s - loss: 0.0357 - accuracy: 0.9907 - val_loss: 5.9468 - val_accuracy: 0.4235\n",
      "Epoch 187/300\n",
      "192/192 - 7s - loss: 0.0558 - accuracy: 0.9853 - val_loss: 8.9263 - val_accuracy: 0.3966\n",
      "Epoch 188/300\n",
      "192/192 - 7s - loss: 0.0462 - accuracy: 0.9876 - val_loss: 6.2429 - val_accuracy: 0.4267\n",
      "Epoch 189/300\n",
      "192/192 - 7s - loss: 0.0480 - accuracy: 0.9868 - val_loss: 5.9627 - val_accuracy: 0.4422\n",
      "Epoch 190/300\n",
      "192/192 - 7s - loss: 0.0330 - accuracy: 0.9894 - val_loss: 5.0014 - val_accuracy: 0.4145\n",
      "Epoch 191/300\n",
      "192/192 - 7s - loss: 0.0371 - accuracy: 0.9910 - val_loss: 5.2166 - val_accuracy: 0.4267\n",
      "Epoch 192/300\n",
      "192/192 - 7s - loss: 0.0369 - accuracy: 0.9906 - val_loss: 8.1018 - val_accuracy: 0.4503\n",
      "Epoch 193/300\n",
      "192/192 - 7s - loss: 0.0368 - accuracy: 0.9896 - val_loss: 6.9466 - val_accuracy: 0.4316\n",
      "Epoch 194/300\n",
      "192/192 - 7s - loss: 0.0335 - accuracy: 0.9906 - val_loss: 7.8682 - val_accuracy: 0.4332\n",
      "Epoch 195/300\n",
      "192/192 - 7s - loss: 0.0403 - accuracy: 0.9896 - val_loss: 5.2953 - val_accuracy: 0.4259\n",
      "Epoch 196/300\n",
      "192/192 - 7s - loss: 0.0542 - accuracy: 0.9862 - val_loss: 5.7567 - val_accuracy: 0.4243\n",
      "Epoch 197/300\n",
      "192/192 - 7s - loss: 0.0380 - accuracy: 0.9901 - val_loss: 6.1778 - val_accuracy: 0.4243\n",
      "Epoch 198/300\n",
      "192/192 - 7s - loss: 0.0428 - accuracy: 0.9891 - val_loss: 5.0039 - val_accuracy: 0.3632\n",
      "Epoch 199/300\n",
      "192/192 - 7s - loss: 0.0325 - accuracy: 0.9906 - val_loss: 5.3317 - val_accuracy: 0.4235\n",
      "Epoch 200/300\n",
      "192/192 - 7s - loss: 0.0515 - accuracy: 0.9873 - val_loss: 6.9292 - val_accuracy: 0.4112\n",
      "Epoch 201/300\n",
      "192/192 - 7s - loss: 0.0554 - accuracy: 0.9865 - val_loss: 6.8704 - val_accuracy: 0.4039\n",
      "Epoch 202/300\n",
      "192/192 - 7s - loss: 0.0631 - accuracy: 0.9855 - val_loss: 7.9372 - val_accuracy: 0.3428\n",
      "Epoch 203/300\n",
      "192/192 - 7s - loss: 0.0471 - accuracy: 0.9868 - val_loss: 6.9138 - val_accuracy: 0.3958\n",
      "Epoch 204/300\n",
      "192/192 - 7s - loss: 0.0467 - accuracy: 0.9857 - val_loss: 7.9842 - val_accuracy: 0.4528\n",
      "Epoch 205/300\n",
      "192/192 - 7s - loss: 0.0358 - accuracy: 0.9894 - val_loss: 8.9840 - val_accuracy: 0.4243\n",
      "Epoch 206/300\n",
      "192/192 - 7s - loss: 0.0561 - accuracy: 0.9863 - val_loss: 7.1006 - val_accuracy: 0.4186\n",
      "Epoch 207/300\n",
      "192/192 - 7s - loss: 0.0348 - accuracy: 0.9902 - val_loss: 9.2291 - val_accuracy: 0.4568\n",
      "Epoch 208/300\n",
      "192/192 - 7s - loss: 0.0471 - accuracy: 0.9881 - val_loss: 6.0192 - val_accuracy: 0.4495\n",
      "Epoch 209/300\n",
      "192/192 - 7s - loss: 0.0226 - accuracy: 0.9948 - val_loss: 7.3012 - val_accuracy: 0.4308\n",
      "Epoch 210/300\n",
      "192/192 - 7s - loss: 0.0306 - accuracy: 0.9930 - val_loss: 11.2251 - val_accuracy: 0.4235\n",
      "Epoch 211/300\n",
      "192/192 - 7s - loss: 0.0319 - accuracy: 0.9915 - val_loss: 9.2898 - val_accuracy: 0.4235\n",
      "Epoch 212/300\n",
      "192/192 - 7s - loss: 0.0444 - accuracy: 0.9891 - val_loss: 8.0720 - val_accuracy: 0.3730\n",
      "Epoch 213/300\n",
      "192/192 - 7s - loss: 0.0466 - accuracy: 0.9865 - val_loss: 5.4252 - val_accuracy: 0.3420\n",
      "Epoch 214/300\n",
      "192/192 - 7s - loss: 0.0399 - accuracy: 0.9889 - val_loss: 6.5404 - val_accuracy: 0.4072\n",
      "Epoch 215/300\n",
      "192/192 - 7s - loss: 0.0310 - accuracy: 0.9889 - val_loss: 7.6242 - val_accuracy: 0.4096\n",
      "Epoch 216/300\n",
      "192/192 - 7s - loss: 0.0369 - accuracy: 0.9884 - val_loss: 7.1357 - val_accuracy: 0.4178\n",
      "Epoch 217/300\n",
      "192/192 - 7s - loss: 0.0512 - accuracy: 0.9870 - val_loss: 8.0268 - val_accuracy: 0.4463\n",
      "Epoch 218/300\n",
      "192/192 - 7s - loss: 0.0565 - accuracy: 0.9875 - val_loss: 5.9385 - val_accuracy: 0.4349\n",
      "Epoch 219/300\n",
      "192/192 - 7s - loss: 0.0432 - accuracy: 0.9888 - val_loss: 8.7924 - val_accuracy: 0.4178\n",
      "Epoch 220/300\n",
      "192/192 - 7s - loss: 0.0328 - accuracy: 0.9912 - val_loss: 6.8963 - val_accuracy: 0.4332\n",
      "Epoch 221/300\n",
      "192/192 - 7s - loss: 0.0376 - accuracy: 0.9901 - val_loss: 8.9917 - val_accuracy: 0.4406\n",
      "Epoch 222/300\n",
      "192/192 - 7s - loss: 0.0319 - accuracy: 0.9923 - val_loss: 7.0892 - val_accuracy: 0.4389\n",
      "Epoch 223/300\n",
      "192/192 - 7s - loss: 0.0350 - accuracy: 0.9909 - val_loss: 6.4460 - val_accuracy: 0.4528\n",
      "Epoch 224/300\n",
      "192/192 - 7s - loss: 0.0455 - accuracy: 0.9901 - val_loss: 8.9981 - val_accuracy: 0.4047\n",
      "Epoch 225/300\n",
      "192/192 - 7s - loss: 0.0508 - accuracy: 0.9876 - val_loss: 6.6385 - val_accuracy: 0.4072\n",
      "Epoch 226/300\n",
      "192/192 - 7s - loss: 0.0316 - accuracy: 0.9915 - val_loss: 6.8682 - val_accuracy: 0.4340\n",
      "Epoch 227/300\n",
      "192/192 - 7s - loss: 0.0228 - accuracy: 0.9935 - val_loss: 8.8853 - val_accuracy: 0.4568\n",
      "Epoch 228/300\n",
      "192/192 - 7s - loss: 0.0381 - accuracy: 0.9906 - val_loss: 5.8788 - val_accuracy: 0.3787\n",
      "Epoch 229/300\n",
      "192/192 - 7s - loss: 0.0385 - accuracy: 0.9904 - val_loss: 7.9788 - val_accuracy: 0.4145\n",
      "Epoch 230/300\n",
      "192/192 - 7s - loss: 0.0375 - accuracy: 0.9888 - val_loss: 8.0130 - val_accuracy: 0.4292\n",
      "Epoch 231/300\n",
      "192/192 - 7s - loss: 0.0428 - accuracy: 0.9901 - val_loss: 11.5075 - val_accuracy: 0.3933\n",
      "Epoch 232/300\n",
      "192/192 - 7s - loss: 0.0545 - accuracy: 0.9871 - val_loss: 6.5423 - val_accuracy: 0.4316\n",
      "Epoch 233/300\n",
      "192/192 - 7s - loss: 0.0351 - accuracy: 0.9917 - val_loss: 8.3060 - val_accuracy: 0.4357\n",
      "Epoch 234/300\n",
      "192/192 - 7s - loss: 0.0471 - accuracy: 0.9878 - val_loss: 6.1424 - val_accuracy: 0.4332\n",
      "Epoch 235/300\n",
      "192/192 - 7s - loss: 0.0272 - accuracy: 0.9920 - val_loss: 8.2560 - val_accuracy: 0.4365\n",
      "Epoch 236/300\n",
      "192/192 - 7s - loss: 0.0278 - accuracy: 0.9915 - val_loss: 6.5226 - val_accuracy: 0.4414\n",
      "Epoch 237/300\n",
      "192/192 - 7s - loss: 0.0372 - accuracy: 0.9917 - val_loss: 5.9570 - val_accuracy: 0.4137\n",
      "Epoch 238/300\n",
      "192/192 - 7s - loss: 0.0302 - accuracy: 0.9925 - val_loss: 7.7337 - val_accuracy: 0.4349\n",
      "Epoch 239/300\n",
      "192/192 - 7s - loss: 0.0344 - accuracy: 0.9927 - val_loss: 7.5044 - val_accuracy: 0.4324\n",
      "Epoch 240/300\n",
      "192/192 - 7s - loss: 0.0243 - accuracy: 0.9930 - val_loss: 7.7878 - val_accuracy: 0.3917\n",
      "Epoch 241/300\n",
      "192/192 - 7s - loss: 0.0351 - accuracy: 0.9907 - val_loss: 7.5917 - val_accuracy: 0.4243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/300\n",
      "192/192 - 7s - loss: 0.0456 - accuracy: 0.9889 - val_loss: 6.9792 - val_accuracy: 0.4381\n",
      "Epoch 243/300\n",
      "192/192 - 7s - loss: 0.0406 - accuracy: 0.9907 - val_loss: 12.2987 - val_accuracy: 0.4324\n",
      "Epoch 244/300\n",
      "192/192 - 7s - loss: 0.0361 - accuracy: 0.9912 - val_loss: 5.5080 - val_accuracy: 0.3909\n",
      "Epoch 245/300\n",
      "192/192 - 7s - loss: 0.0361 - accuracy: 0.9899 - val_loss: 8.7413 - val_accuracy: 0.4316\n",
      "Epoch 246/300\n",
      "192/192 - 7s - loss: 0.0437 - accuracy: 0.9889 - val_loss: 7.4487 - val_accuracy: 0.4300\n",
      "Epoch 247/300\n",
      "192/192 - 7s - loss: 0.0372 - accuracy: 0.9878 - val_loss: 8.7804 - val_accuracy: 0.3958\n",
      "Epoch 248/300\n",
      "192/192 - 7s - loss: 0.0426 - accuracy: 0.9907 - val_loss: 8.4990 - val_accuracy: 0.4194\n",
      "Epoch 249/300\n",
      "192/192 - 7s - loss: 0.0328 - accuracy: 0.9920 - val_loss: 7.3720 - val_accuracy: 0.4463\n",
      "Epoch 250/300\n",
      "192/192 - 7s - loss: 0.0389 - accuracy: 0.9883 - val_loss: 8.3855 - val_accuracy: 0.4283\n",
      "Epoch 251/300\n",
      "192/192 - 7s - loss: 0.0428 - accuracy: 0.9891 - val_loss: 6.9915 - val_accuracy: 0.4169\n",
      "Epoch 252/300\n",
      "192/192 - 7s - loss: 0.0322 - accuracy: 0.9917 - val_loss: 8.2162 - val_accuracy: 0.4324\n",
      "Epoch 253/300\n",
      "192/192 - 7s - loss: 0.0338 - accuracy: 0.9919 - val_loss: 6.0636 - val_accuracy: 0.4218\n",
      "Epoch 254/300\n",
      "192/192 - 7s - loss: 0.0349 - accuracy: 0.9923 - val_loss: 8.4623 - val_accuracy: 0.4235\n",
      "Epoch 255/300\n",
      "192/192 - 7s - loss: 0.0476 - accuracy: 0.9899 - val_loss: 8.3907 - val_accuracy: 0.4259\n",
      "Epoch 256/300\n",
      "192/192 - 7s - loss: 0.0455 - accuracy: 0.9896 - val_loss: 9.1387 - val_accuracy: 0.4226\n",
      "Epoch 257/300\n",
      "192/192 - 7s - loss: 0.0345 - accuracy: 0.9912 - val_loss: 8.2644 - val_accuracy: 0.4560\n",
      "Epoch 258/300\n",
      "192/192 - 7s - loss: 0.0361 - accuracy: 0.9904 - val_loss: 8.6778 - val_accuracy: 0.4365\n",
      "Epoch 259/300\n",
      "192/192 - 7s - loss: 0.0288 - accuracy: 0.9935 - val_loss: 5.7240 - val_accuracy: 0.4015\n",
      "Epoch 260/300\n",
      "192/192 - 7s - loss: 0.0252 - accuracy: 0.9928 - val_loss: 9.7946 - val_accuracy: 0.4479\n",
      "Epoch 261/300\n",
      "192/192 - 7s - loss: 0.0289 - accuracy: 0.9930 - val_loss: 6.5055 - val_accuracy: 0.4381\n",
      "Epoch 262/300\n",
      "192/192 - 7s - loss: 0.0320 - accuracy: 0.9938 - val_loss: 7.0663 - val_accuracy: 0.4194\n",
      "Epoch 263/300\n",
      "192/192 - 7s - loss: 0.0351 - accuracy: 0.9927 - val_loss: 7.1620 - val_accuracy: 0.4194\n",
      "Epoch 264/300\n",
      "192/192 - 7s - loss: 0.0459 - accuracy: 0.9886 - val_loss: 14.9794 - val_accuracy: 0.3355\n",
      "Epoch 265/300\n",
      "192/192 - 7s - loss: 0.0428 - accuracy: 0.9899 - val_loss: 9.6362 - val_accuracy: 0.3974\n",
      "Epoch 266/300\n",
      "192/192 - 7s - loss: 0.0268 - accuracy: 0.9936 - val_loss: 6.1583 - val_accuracy: 0.3705\n",
      "Epoch 267/300\n",
      "192/192 - 7s - loss: 0.0210 - accuracy: 0.9943 - val_loss: 9.1315 - val_accuracy: 0.4495\n",
      "Epoch 268/300\n",
      "192/192 - 7s - loss: 0.0322 - accuracy: 0.9932 - val_loss: 7.9376 - val_accuracy: 0.4226\n",
      "Epoch 269/300\n",
      "192/192 - 7s - loss: 0.0313 - accuracy: 0.9927 - val_loss: 9.3320 - val_accuracy: 0.4292\n",
      "Epoch 270/300\n",
      "192/192 - 7s - loss: 0.0308 - accuracy: 0.9922 - val_loss: 7.4236 - val_accuracy: 0.4235\n",
      "Epoch 271/300\n",
      "192/192 - 7s - loss: 0.0242 - accuracy: 0.9930 - val_loss: 6.1268 - val_accuracy: 0.3852\n",
      "Epoch 272/300\n",
      "192/192 - 7s - loss: 0.0479 - accuracy: 0.9889 - val_loss: 12.7528 - val_accuracy: 0.4275\n",
      "Epoch 273/300\n",
      "192/192 - 7s - loss: 0.0394 - accuracy: 0.9912 - val_loss: 10.5293 - val_accuracy: 0.4381\n",
      "Epoch 274/300\n",
      "192/192 - 7s - loss: 0.0211 - accuracy: 0.9943 - val_loss: 9.2108 - val_accuracy: 0.3990\n",
      "Epoch 275/300\n",
      "192/192 - 7s - loss: 0.0253 - accuracy: 0.9943 - val_loss: 10.1629 - val_accuracy: 0.4308\n",
      "Epoch 276/300\n",
      "192/192 - 7s - loss: 0.0209 - accuracy: 0.9941 - val_loss: 8.5535 - val_accuracy: 0.4137\n",
      "Epoch 277/300\n",
      "192/192 - 7s - loss: 0.0352 - accuracy: 0.9938 - val_loss: 8.1352 - val_accuracy: 0.4308\n",
      "Epoch 278/300\n",
      "192/192 - 7s - loss: 0.0271 - accuracy: 0.9936 - val_loss: 6.6738 - val_accuracy: 0.3453\n",
      "Epoch 279/300\n",
      "192/192 - 7s - loss: 0.0322 - accuracy: 0.9919 - val_loss: 8.9218 - val_accuracy: 0.4072\n",
      "Epoch 280/300\n",
      "192/192 - 7s - loss: 0.0399 - accuracy: 0.9910 - val_loss: 11.4704 - val_accuracy: 0.4373\n",
      "Epoch 281/300\n",
      "192/192 - 7s - loss: 0.0288 - accuracy: 0.9928 - val_loss: 7.2166 - val_accuracy: 0.4137\n",
      "Epoch 282/300\n",
      "192/192 - 7s - loss: 0.0231 - accuracy: 0.9941 - val_loss: 9.1599 - val_accuracy: 0.4357\n",
      "Epoch 283/300\n",
      "192/192 - 7s - loss: 0.0370 - accuracy: 0.9902 - val_loss: 11.2076 - val_accuracy: 0.3591\n",
      "Epoch 284/300\n",
      "192/192 - 7s - loss: 0.0506 - accuracy: 0.9894 - val_loss: 10.6564 - val_accuracy: 0.4031\n",
      "Epoch 285/300\n",
      "192/192 - 7s - loss: 0.0289 - accuracy: 0.9919 - val_loss: 9.0178 - val_accuracy: 0.4275\n",
      "Epoch 286/300\n",
      "192/192 - 7s - loss: 0.0382 - accuracy: 0.9925 - val_loss: 8.3987 - val_accuracy: 0.4373\n",
      "Epoch 287/300\n",
      "192/192 - 7s - loss: 0.0323 - accuracy: 0.9923 - val_loss: 9.9987 - val_accuracy: 0.4275\n",
      "Epoch 288/300\n",
      "192/192 - 7s - loss: 0.0454 - accuracy: 0.9893 - val_loss: 8.7319 - val_accuracy: 0.4373\n",
      "Epoch 289/300\n",
      "192/192 - 7s - loss: 0.0248 - accuracy: 0.9938 - val_loss: 11.3004 - val_accuracy: 0.4178\n",
      "Epoch 290/300\n",
      "192/192 - 7s - loss: 0.0498 - accuracy: 0.9906 - val_loss: 10.0055 - val_accuracy: 0.4169\n",
      "Epoch 291/300\n",
      "192/192 - 7s - loss: 0.0592 - accuracy: 0.9863 - val_loss: 6.9795 - val_accuracy: 0.3803\n",
      "Epoch 292/300\n",
      "192/192 - 7s - loss: 0.0354 - accuracy: 0.9912 - val_loss: 7.2621 - val_accuracy: 0.4161\n",
      "Epoch 293/300\n",
      "192/192 - 7s - loss: 0.0416 - accuracy: 0.9902 - val_loss: 6.7421 - val_accuracy: 0.3656\n",
      "Epoch 294/300\n",
      "192/192 - 7s - loss: 0.0404 - accuracy: 0.9919 - val_loss: 10.3369 - val_accuracy: 0.4479\n",
      "Epoch 295/300\n",
      "192/192 - 7s - loss: 0.0217 - accuracy: 0.9943 - val_loss: 8.3760 - val_accuracy: 0.4178\n",
      "Epoch 296/300\n",
      "192/192 - 7s - loss: 0.0275 - accuracy: 0.9928 - val_loss: 13.1835 - val_accuracy: 0.4316\n",
      "Epoch 297/300\n",
      "192/192 - 7s - loss: 0.0394 - accuracy: 0.9922 - val_loss: 11.5885 - val_accuracy: 0.4373\n",
      "Epoch 298/300\n",
      "192/192 - 7s - loss: 0.0313 - accuracy: 0.9930 - val_loss: 8.1732 - val_accuracy: 0.4096\n",
      "Epoch 299/300\n",
      "192/192 - 7s - loss: 0.0271 - accuracy: 0.9950 - val_loss: 10.2929 - val_accuracy: 0.4503\n",
      "Epoch 300/300\n",
      "192/192 - 7s - loss: 0.0267 - accuracy: 0.9932 - val_loss: 9.1230 - val_accuracy: 0.4438\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\yisi9\\AppData\\Local\\Temp\\tmpb30azfs4\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yisi9\\AppData\\Local\\Temp\\tmpb30azfs4\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 1s - loss: 7.9814 - accuracy: 0.4646\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'irep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-691ac190ab4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"repetition\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mirep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"validation_samples\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_samples\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'irep' is not defined"
     ]
    }
   ],
   "source": [
    "mlflow.keras.autolog()\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "        \n",
    "        #model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "        #optimizer=tf.keras.optimizers.Adam(),\n",
    "        #metrics=['accuracy'])\n",
    "        # Fit our model\n",
    "        mlflow.tensorflow.autolog()\n",
    "        \n",
    "        history = model.fit(image_train, label_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(image_val, label_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "        score = model.evaluate(image_test, label_test, batch_size=batch_size, verbose = verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        mlflow.log_param(\"activation function\", act)\n",
    "        mlflow.log_metric(\"test loss\", score[0])\n",
    "        mlflow.log_metric(\"test accuracy\", score[1])\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        \n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        #mlflow.keras.log_model(model, \"standardCNN\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "209e3b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\yisi9\\.conda\\envs\\tf3080\\Scripts\\mlflow.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\click\\core.py\", line 1137, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\click\\core.py\", line 1062, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\click\\core.py\", line 1668, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\click\\core.py\", line 763, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\mlflow\\cli.py\", line 280, in ui\n",
      "    _run_server(backend_store_uri, default_artifact_root, host, port, None, 1)\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\mlflow\\server\\__init__.py\", line 138, in _run_server\n",
      "    exec_cmd(full_command, env=env_map, stream_output=True)\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\site-packages\\mlflow\\utils\\process.py\", line 34, in exec_cmd\n",
      "    child = subprocess.Popen(\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\users\\yisi9\\.conda\\envs\\tf3080\\lib\\subprocess.py\", line 1420, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --backend-store-uri file:///C:\\Users\\yisi9\\.conda\\envs\\tf3080\\mlflow-server\\mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e64051ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: mlflow server [OPTIONS]\n",
      "Try 'mlflow server --help' for help.\n",
      "\n",
      "Error: Got unexpected extra arguments (default-artifact-root file:///C:\\Users\\yisi9\\.conda\\envs\\tf3080\\mlflow-server\\mlruns)\n"
     ]
    }
   ],
   "source": [
    "!mlflow server --backend-store-uri file:///C:\\Users\\yisi9\\.conda\\envs\\tf3080\\mlflow-server\\mlruns -- default-artifact-root file:///C:\\Users\\yisi9\\.conda\\envs\\tf3080\\mlflow-server\\mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db851db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow server [OPTIONS]\n",
      "\n",
      "  Run the MLflow tracking server.\n",
      "\n",
      "  The server which listen on http://localhost:5000 by default, and only accept\n",
      "  connections from the local machine. To let the server accept connections\n",
      "  from other machines, you will need to pass ``--host 0.0.0.0`` to listen on\n",
      "  all network interfaces (or a specific interface address).\n",
      "\n",
      "Options:\n",
      "  --backend-store-uri PATH     URI to which to persist experiment and run\n",
      "                               data. Acceptable URIs are SQLAlchemy-compatible\n",
      "                               database connection strings (e.g.\n",
      "                               'sqlite:///path/to/file.db') or local\n",
      "                               filesystem URIs (e.g.\n",
      "                               'file:///absolute/path/to/directory'). By\n",
      "                               default, data will be logged to the ./mlruns\n",
      "                               directory.\n",
      "  --default-artifact-root URI  Local or S3 URI to store artifacts, for new\n",
      "                               experiments. Note that this flag does not\n",
      "                               impact already-created experiments. Default:\n",
      "                               Within file store, if a file:/ URI is provided.\n",
      "                               If a sql backend is used, then this option is\n",
      "                               required.\n",
      "  -h, --host HOST              The network address to listen on (default:\n",
      "                               127.0.0.1). Use 0.0.0.0 to bind to all\n",
      "                               addresses if you want to access the tracking\n",
      "                               server from other machines.\n",
      "  -p, --port INTEGER           The port to listen on (default: 5000).\n",
      "  -w, --workers TEXT           Number of gunicorn worker processes to handle\n",
      "                               requests (default: 4).\n",
      "  --static-prefix TEXT         A prefix which will be prepended to the path of\n",
      "                               all static paths.\n",
      "  --gunicorn-opts TEXT         Additional command line options forwarded to\n",
      "                               gunicorn processes.\n",
      "  --waitress-opts TEXT         Additional command line options for waitress-\n",
      "                               serve.\n",
      "  --expose-prometheus TEXT     Path to the directory where metrics will be\n",
      "                               stored. If the directory doesn't exist, it will\n",
      "                               be created. Activate prometheus exporter to\n",
      "                               expose metrics on /metrics endpoint.\n",
      "  --help                       Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!mlflow server --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b1f5962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef9ac114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 11ms/step - loss: 2.8771 - accuracy: 0.3927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8770852088928223, 0.3926829397678375]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function that returns loss value & metrics values\n",
    "model.evaluate(image_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b3ec96c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db31c612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12888), started 2 days, 7:29:59 ago. (Use '!kill 12888' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-44fa9b68cb0bef19\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-44fa9b68cb0bef19\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86168ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(image_test, model):\n",
    "    #going through each of the test images\n",
    "    count = 0\n",
    "    for i in range(len(image_test)): #going through all test images\n",
    "        img = image_test[i] #load in the image\n",
    "        \n",
    "        img = img.reshape(-1, 100, 100, 3) #get it in the right shape for model.predict\n",
    "        \n",
    "        prediction = model.predict(img).flatten() #using model predict to get what it thinks is the answer\n",
    "        \n",
    "        # prediction.astype(np.int) #converts predictions to integers\n",
    "        \n",
    "        pred_index = np.argmax(prediction) # grabs the INDEX of the best prediction\n",
    "        \n",
    "        max_pred = max(prediction) # grabs the SCORE of best prediction\n",
    "        # print(prediction)\n",
    "        # print(pred_index)\n",
    "        \n",
    "        test_label_value = label_test[i][pred_index] # gets the actual test label at the same index\n",
    "        # print(test_label_value)\n",
    "        if test_label_value == 1:\n",
    "            #print(\"CORRECT PREDICTION\")\n",
    "            count += 1\n",
    "            \n",
    "#         # FIND THE INDEX WHERE THE VALUE = 1\n",
    "#         for j in range(len(predicted_label)):\n",
    "#             if predicted_label[j] == 1 : #find the point when it finds 1 \n",
    "#                 if label_test[i][j] == 1: #check if at this exact point is also 1  whic means correct prediction\n",
    "#                     count+=1 #increase number of correct count by 1\n",
    "#                     print(count)\n",
    "#                     break\n",
    "    print(f\"num correct - {count}\")\n",
    "    accuracy = (count/len(label_test))*100\n",
    "    per_symbol = '%'\n",
    "    print(f'accuracy is {accuracy} {per_symbol}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "446de09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 224, 224, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19ad03f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 150528 into shape (100,100,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-ddadfef6b03a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-68-e8b78b7d7964>\u001b[0m in \u001b[0;36mprediction_accuracy\u001b[1;34m(image_test, model)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#load in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get it in the right shape for model.predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#using model predict to get what it thinks is the answer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 150528 into shape (100,100,3)"
     ]
    }
   ],
   "source": [
    "prediction_accuracy(image_test, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks for best model\n",
    "runs = mlflow.search_runs(experiment_ids=experiment_id,\n",
    "                          order_by=['metrics.mae'], max_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1d438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8233bce6",
   "metadata": {},
   "source": [
    "# Segmentation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599480db",
   "metadata": {},
   "source": [
    "# MASK RCNN CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d290bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"E:\\Dissertation\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"data\\img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bfc39",
   "metadata": {},
   "source": [
    "## Extract Masks from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e724bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all the image paths stores in a list\n",
    "def get_img_paths(URL_dir):\n",
    "    img_paths = []\n",
    "    for path in os.listdir(URL_dir):\n",
    "        full_path = os.path.join(URL_dir, path)\n",
    "        if os.path.isfile(full_path):\n",
    "            img_paths.append(full_path)\n",
    "\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34762a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = get_img_paths(URL_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b974129",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plots each object on a copy of the image and attempts to remove noise\n",
    "\n",
    "def plot_mask(image, masks):\n",
    "    all_masks = list()\n",
    "    masks = masks.astype(int)\n",
    "    # print(masks.shape)\n",
    "    \n",
    "    for i in range(masks.shape[2]):\n",
    "        temp = np.copy(image)\n",
    "        for j in range(temp.shape[2]):\n",
    "            temp[:,:,j] = temp[:,:,j] * masks[:,:,i]\n",
    "        all_masks.append(temp)\n",
    "#         plt.figure(figsize=(8,8))\n",
    "#         plt.imshow(temp)\n",
    "    # print(f\"Number of masks: {len(all_masks)}\")\n",
    "    return all_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665be4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overlay all masks onto a black canvas\n",
    "\n",
    "def combine_mask_objects(masks, shape):\n",
    "    canvas = np.zeros(shape, np.uint8)\n",
    "#     print(\"ORIGINAL CANVAS\")\n",
    "#     plt.figure(figsize=(8,8))\n",
    "#     plt.imshow(canvas)\n",
    "    for i, obj in enumerate(masks):\n",
    "        canvas = cv2.add(canvas, obj)\n",
    "#         plt.figure(figsize=(8,8))\n",
    "#         plt.imshow(canvas)\n",
    "    return canvas\n",
    "\n",
    "### Saves all masks for each image in a separate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(img_id, img, folder):\n",
    "    # checks if the img_id folder exists, if not create one\n",
    "    img = PIL.Image.fromarray(img, 'RGB')\n",
    "    img.save(f'{folder}/{img_id}.png')\n",
    "    return True       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8978a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_masks(folder_name, img_paths):\n",
    "    # checks if the masks folder exists, if not creates one\n",
    "    print(os.getcwd())\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    for img_path in img_paths:\n",
    "        print(img_path)\n",
    "        img_id = Path(img_path).stem\n",
    "        print(img_id)\n",
    "        image = skimage.io.imread(img_path)\n",
    "        # check if image is in rgba format\n",
    "        if image.shape[2] > 3:\n",
    "            # convert to rgb\n",
    "            image = rgba2rgb(image)\n",
    "        # Run detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        # Visualize results\n",
    "        r = results[0]\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], UNIQUE_LABELS, r['scores'])\n",
    "\n",
    "        masks = plot_mask(np.copy(image), r[\"masks\"])\n",
    "\n",
    "        if len(masks) > 0:\n",
    "            processed_image = combine_mask_objects(masks, masks[0].shape)\n",
    "            print(masks)\n",
    "            save_image(i, processed_image, folder_name)\n",
    "        else:\n",
    "            print(f\"{img_id} has no masks!\")\n",
    "            save_image(img_id, image, folder_name)\n",
    "    return \"COMPLETE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(\"E:\\Dissertation\")\n",
    "# os.chdir(path)\n",
    "# UNCOMMENT THIS LINE TO EXTRACT MASKS FROM DATATSET\n",
    "# BEWARE THIS PROCESS CAN TAKE HOURS TO FINISH!\n",
    "generate_masks(\"masks\", img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MASK_DIR = os.path.join(MAIN_PATH, 'data\\train_masks')\n",
    "DEV_SEEN_MASK_DIR = os.path.join(MAIN_PATH, 'data\\dev_seen_masks')\n",
    "DEV_UNSEEN_MASK_DIR = os.path.join(MAIN_PATH, 'data\\dev_unseen_masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce7b56",
   "metadata": {},
   "source": [
    "# 3. Create feature vector of object masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d13d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def extract_id(name):\n",
    "    filename = Path(name).stem\n",
    "    # print(filename)\n",
    "    return filename\n",
    "\n",
    "def generate_data(df, directory):\n",
    "    # dataset con\n",
    "    ids = df[\"id\"].to_numpy()\n",
    "    labels = df[\"label\"].to_numpy()\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        print(root)\n",
    "        count = 0\n",
    "        for file in tqdm(files):\n",
    "            # print(f\"IMAGE: {file}\")\n",
    "            # get full path of the mask\n",
    "            full_path = os.path.join(root, file)\n",
    "            # extract the image id from file\n",
    "            img_id = extract_id(file)\n",
    "            # get tensor of the mask\n",
    "            image = Image.open(full_path)\n",
    "            image = image.resize((224, 224))\n",
    "            image_vect = np.asarray(image)\n",
    "            # print(image_vect.shape)\n",
    "            # find the index for the image_id\n",
    "            idx = np.where(ids == int(img_id))[0][0]\n",
    "            # print(df.iloc[idx])\n",
    "\n",
    "            # get the label for that image_id\n",
    "            label = labels[idx]\n",
    "\n",
    "            # Append features and labels to data lists\n",
    "            X.append(image_vect)\n",
    "            y.append(label)\n",
    "        break\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = generate_data(TRAIN_DF, TRAIN_MASK_DIR)\n",
    "\n",
    "# uncomment to generate training data for dev masks\n",
    "# X, y = generate_data(DEV_SEEN_DF, DEV_SEEN_MASK_DIR)\n",
    "# X, y = generate_data(DEV_UNSEEN_DF, DEV_UNSEEN_MASK_DIR)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c5b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335db64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedd41cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29721ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad216f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43996e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc119a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1364a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a01fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704716c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb928e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28e2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b90d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b52e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4a541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335092d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd45548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649833bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b8c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
